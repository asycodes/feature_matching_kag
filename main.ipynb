{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "146c6139-f219-40f5-aa7c-76cba31ed42b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/asyra/Projects/feature_matching_kag/.pyenv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Using cache found in /home/asy/.cache/torch/hub/facebookresearch_dinov2_main\n",
      "/home/asy/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/swiglu_ffn.py:43: UserWarning: xFormers is available (SwiGLU)\n",
      "  warnings.warn(\"xFormers is available (SwiGLU)\")\n",
      "/home/asy/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/attention.py:27: UserWarning: xFormers is available (Attention)\n",
      "  warnings.warn(\"xFormers is available (Attention)\")\n",
      "/home/asy/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/block.py:33: UserWarning: xFormers is available (Block)\n",
      "  warnings.warn(\"xFormers is available (Block)\")\n",
      "`use_fast` is set to `True` but the image processor class does not have a fast version.  Falling back to the slow version.\n"
     ]
    }
   ],
   "source": [
    "import os, math, glob\n",
    "os.environ[\"TRANSFORMERS_NO_TF\"] = \"1\"\n",
    "os.environ[\"TRANSFORMERS_NO_FLAX\"] = \"1\"\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from transformers import AutoProcessor, AutoModel\n",
    "import networkx as nx\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.cm import get_cmap\n",
    "from sklearn.decomposition import PCA\n",
    "import faiss\n",
    "import pycolmap\n",
    "import os\n",
    "import sqlite3\n",
    "from collections import defaultdict\n",
    "from scipy.spatial import cKDTree\n",
    "import h5py\n",
    "from pathlib import Path\n",
    "\n",
    "\"\"\"\n",
    "1) Global feature matching using DINOV2\n",
    "- to reduce error propagation use PCA-whitening :why? -> essentially to remove redundent patterns, and highlight more meaningful patterns\n",
    "- use FAISS HNSW and query top-K neighbors, Faiss for similarity search, finding similarity based on THOSE meaningful patterns. and query top-k neighbours amongst the candidates from similarity search\n",
    "\n",
    "- https://www.researchgate.net/publication/259624676_Negative_Evidences_and_Co-occurences_in_Image_Retrieval_The_Benefit_of_PCA_and_Whitening\n",
    "2) use the image pairings from DINOV2 \n",
    "3) Within each image pairings do:\n",
    "    1) set longside to 960px and max keypoinys to 4096,superpoint for extraction then LightGlue (feature matching)\n",
    "    2) insert pair into colmap to do geometric verification using RANSAC or do manual: Do Ransaac to do geometric verification of each match (remove outliers through sampson approx -> https://arxiv.org/abs/2401.07114)\n",
    "4) pycolmap\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "global_model = torch.hub.load('facebookresearch/dinov2', 'dinov2_vitg14').to(device).eval()\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize(518, interpolation=transforms.InterpolationMode.BICUBIC),\n",
    "    transforms.CenterCrop(518),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=(0.485, 0.456, 0.406),\n",
    "                         std=(0.229, 0.224, 0.225)),\n",
    "])\n",
    "local_processor = AutoProcessor.from_pretrained(\"ETH-CVG/lightglue_superpoint\",use_fast=True)\n",
    "local_model = AutoModel.from_pretrained(\"ETH-CVG/lightglue_superpoint\").to(device).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b278084d-196a-40fe-aa04-110685ef17bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PCA] Reducing out_dim from 256 -> 21 (N=22, D=1536)\n",
      "[('test/ETs/et_et005.png', 'test/ETs/outliers_out_et003.png'), ('test/ETs/another_et_another_et007.png', 'test/ETs/et_et008.png'), ('test/ETs/et_et006.png', 'test/ETs/outliers_out_et002.png'), ('test/ETs/another_et_another_et008.png', 'test/ETs/et_et007.png'), ('test/ETs/another_et_another_et005.png', 'test/ETs/another_et_another_et010.png'), ('test/ETs/another_et_another_et004.png', 'test/ETs/et_et003.png'), ('test/ETs/another_et_another_et006.png', 'test/ETs/et_et000.png'), ('test/ETs/another_et_another_et009.png', 'test/ETs/another_et_another_et010.png'), ('test/ETs/another_et_another_et001.png', 'test/ETs/another_et_another_et006.png'), ('test/ETs/another_et_another_et006.png', 'test/ETs/outliers_out_et001.png'), ('test/ETs/another_et_another_et009.png', 'test/ETs/et_et008.png'), ('test/ETs/et_et007.png', 'test/ETs/outliers_out_et003.png'), ('test/ETs/another_et_another_et010.png', 'test/ETs/et_et007.png'), ('test/ETs/another_et_another_et001.png', 'test/ETs/et_et004.png'), ('test/ETs/another_et_another_et003.png', 'test/ETs/et_et001.png'), ('test/ETs/et_et001.png', 'test/ETs/et_et004.png'), ('test/ETs/another_et_another_et002.png', 'test/ETs/et_et005.png'), ('test/ETs/et_et003.png', 'test/ETs/et_et007.png'), ('test/ETs/another_et_another_et007.png', 'test/ETs/et_et001.png'), ('test/ETs/another_et_another_et008.png', 'test/ETs/et_et000.png'), ('test/ETs/another_et_another_et007.png', 'test/ETs/outliers_out_et002.png'), ('test/ETs/another_et_another_et008.png', 'test/ETs/outliers_out_et001.png'), ('test/ETs/et_et008.png', 'test/ETs/outliers_out_et001.png'), ('test/ETs/another_et_another_et004.png', 'test/ETs/another_et_another_et007.png'), ('test/ETs/et_et002.png', 'test/ETs/et_et008.png'), ('test/ETs/another_et_another_et004.png', 'test/ETs/et_et005.png'), ('test/ETs/another_et_another_et006.png', 'test/ETs/et_et002.png'), ('test/ETs/another_et_another_et009.png', 'test/ETs/et_et001.png'), ('test/ETs/et_et004.png', 'test/ETs/et_et005.png'), ('test/ETs/another_et_another_et010.png', 'test/ETs/et_et000.png'), ('test/ETs/another_et_another_et001.png', 'test/ETs/another_et_another_et008.png'), ('test/ETs/another_et_another_et003.png', 'test/ETs/another_et_another_et005.png'), ('test/ETs/another_et_another_et006.png', 'test/ETs/outliers_out_et003.png'), ('test/ETs/another_et_another_et010.png', 'test/ETs/outliers_out_et001.png'), ('test/ETs/another_et_another_et001.png', 'test/ETs/et_et006.png'), ('test/ETs/et_et001.png', 'test/ETs/et_et006.png'), ('test/ETs/another_et_another_et002.png', 'test/ETs/another_et_another_et009.png'), ('test/ETs/et_et000.png', 'test/ETs/outliers_out_et002.png'), ('test/ETs/another_et_another_et002.png', 'test/ETs/et_et007.png'), ('test/ETs/et_et003.png', 'test/ETs/outliers_out_et001.png'), ('test/ETs/another_et_another_et007.png', 'test/ETs/et_et003.png'), ('test/ETs/et_et005.png', 'test/ETs/et_et006.png'), ('test/ETs/another_et_another_et008.png', 'test/ETs/et_et002.png'), ('test/ETs/another_et_another_et008.png', 'test/ETs/outliers_out_et003.png'), ('test/ETs/et_et008.png', 'test/ETs/outliers_out_et003.png'), ('test/ETs/another_et_another_et004.png', 'test/ETs/another_et_another_et009.png'), ('test/ETs/et_et002.png', 'test/ETs/outliers_out_et002.png'), ('test/ETs/another_et_another_et004.png', 'test/ETs/et_et007.png'), ('test/ETs/another_et_another_et006.png', 'test/ETs/et_et004.png'), ('test/ETs/et_et004.png', 'test/ETs/et_et007.png'), ('test/ETs/another_et_another_et010.png', 'test/ETs/et_et002.png'), ('test/ETs/another_et_another_et001.png', 'test/ETs/another_et_another_et010.png'), ('test/ETs/another_et_another_et010.png', 'test/ETs/outliers_out_et003.png'), ('test/ETs/another_et_another_et002.png', 'test/ETs/et_et000.png'), ('test/ETs/another_et_another_et002.png', 'test/ETs/outliers_out_et001.png'), ('test/ETs/et_et003.png', 'test/ETs/outliers_out_et003.png'), ('test/ETs/et_et005.png', 'test/ETs/et_et008.png'), ('test/ETs/et_et006.png', 'test/ETs/et_et007.png'), ('test/ETs/another_et_another_et008.png', 'test/ETs/et_et004.png'), ('test/ETs/et_et002.png', 'test/ETs/et_et003.png'), ('test/ETs/another_et_another_et004.png', 'test/ETs/et_et000.png'), ('test/ETs/another_et_another_et006.png', 'test/ETs/another_et_another_et008.png'), ('test/ETs/another_et_another_et001.png', 'test/ETs/another_et_another_et003.png'), ('test/ETs/another_et_another_et004.png', 'test/ETs/outliers_out_et001.png'), ('test/ETs/another_et_another_et005.png', 'test/ETs/et_et008.png'), ('test/ETs/another_et_another_et006.png', 'test/ETs/et_et006.png'), ('test/ETs/another_et_another_et010.png', 'test/ETs/et_et004.png'), ('test/ETs/et_et004.png', 'test/ETs/outliers_out_et001.png'), ('test/ETs/another_et_another_et002.png', 'test/ETs/another_et_another_et004.png'), ('test/ETs/et_et000.png', 'test/ETs/et_et005.png'), ('test/ETs/another_et_another_et002.png', 'test/ETs/et_et002.png'), ('test/ETs/et_et003.png', 'test/ETs/et_et004.png'), ('test/ETs/another_et_another_et002.png', 'test/ETs/outliers_out_et003.png'), ('test/ETs/another_et_another_et003.png', 'test/ETs/outliers_out_et002.png'), ('test/ETs/et_et006.png', 'test/ETs/outliers_out_et001.png'), ('test/ETs/another_et_another_et008.png', 'test/ETs/et_et006.png'), ('test/ETs/et_et002.png', 'test/ETs/et_et005.png'), ('test/ETs/another_et_another_et004.png', 'test/ETs/et_et002.png'), ('test/ETs/another_et_another_et006.png', 'test/ETs/another_et_another_et010.png'), ('test/ETs/another_et_another_et005.png', 'test/ETs/et_et001.png'), ('test/ETs/another_et_another_et004.png', 'test/ETs/outliers_out_et003.png'), ('test/ETs/another_et_another_et006.png', 'test/ETs/et_et008.png'), ('test/ETs/another_et_another_et005.png', 'test/ETs/outliers_out_et002.png'), ('test/ETs/et_et004.png', 'test/ETs/outliers_out_et003.png'), ('test/ETs/another_et_another_et010.png', 'test/ETs/et_et006.png'), ('test/ETs/another_et_another_et002.png', 'test/ETs/another_et_another_et006.png'), ('test/ETs/another_et_another_et009.png', 'test/ETs/outliers_out_et002.png'), ('test/ETs/et_et000.png', 'test/ETs/et_et007.png'), ('test/ETs/another_et_another_et002.png', 'test/ETs/et_et004.png'), ('test/ETs/et_et003.png', 'test/ETs/et_et006.png'), ('test/ETs/another_et_another_et003.png', 'test/ETs/et_et003.png'), ('test/ETs/outliers_out_et001.png', 'test/ETs/outliers_out_et002.png'), ('test/ETs/another_et_another_et008.png', 'test/ETs/another_et_another_et010.png'), ('test/ETs/et_et006.png', 'test/ETs/outliers_out_et003.png'), ('test/ETs/another_et_another_et004.png', 'test/ETs/another_et_another_et006.png'), ('test/ETs/outliers_out_et002.png', 'test/ETs/outliers_out_et003.png'), ('test/ETs/et_et002.png', 'test/ETs/et_et007.png'), ('test/ETs/another_et_another_et004.png', 'test/ETs/et_et004.png'), ('test/ETs/another_et_another_et006.png', 'test/ETs/et_et001.png'), ('test/ETs/another_et_another_et005.png', 'test/ETs/et_et003.png'), ('test/ETs/another_et_another_et009.png', 'test/ETs/et_et003.png'), ('test/ETs/another_et_another_et002.png', 'test/ETs/another_et_another_et008.png'), ('test/ETs/another_et_another_et003.png', 'test/ETs/another_et_another_et007.png'), ('test/ETs/et_et000.png', 'test/ETs/outliers_out_et001.png'), ('test/ETs/another_et_another_et002.png', 'test/ETs/et_et006.png'), ('test/ETs/another_et_another_et001.png', 'test/ETs/et_et008.png'), ('test/ETs/another_et_another_et003.png', 'test/ETs/et_et005.png'), ('test/ETs/et_et001.png', 'test/ETs/et_et008.png'), ('test/ETs/another_et_another_et008.png', 'test/ETs/et_et001.png'), ('test/ETs/et_et003.png', 'test/ETs/et_et008.png'), ('test/ETs/another_et_another_et007.png', 'test/ETs/et_et005.png'), ('test/ETs/another_et_another_et004.png', 'test/ETs/another_et_another_et008.png'), ('test/ETs/another_et_another_et005.png', 'test/ETs/another_et_another_et007.png'), ('test/ETs/et_et002.png', 'test/ETs/outliers_out_et001.png'), ('test/ETs/another_et_another_et004.png', 'test/ETs/et_et006.png'), ('test/ETs/another_et_another_et006.png', 'test/ETs/et_et003.png'), ('test/ETs/another_et_another_et005.png', 'test/ETs/et_et005.png'), ('test/ETs/et_et004.png', 'test/ETs/et_et006.png'), ('test/ETs/et_et007.png', 'test/ETs/outliers_out_et001.png'), ('test/ETs/et_et007.png', 'test/ETs/et_et008.png'), ('test/ETs/another_et_another_et009.png', 'test/ETs/et_et005.png'), ('test/ETs/et_et000.png', 'test/ETs/et_et002.png'), ('test/ETs/another_et_another_et002.png', 'test/ETs/another_et_another_et010.png'), ('test/ETs/another_et_another_et001.png', 'test/ETs/et_et001.png'), ('test/ETs/another_et_another_et003.png', 'test/ETs/another_et_another_et009.png'), ('test/ETs/et_et000.png', 'test/ETs/outliers_out_et003.png'), ('test/ETs/another_et_another_et002.png', 'test/ETs/et_et008.png'), ('test/ETs/another_et_another_et001.png', 'test/ETs/outliers_out_et002.png'), ('test/ETs/another_et_another_et003.png', 'test/ETs/et_et007.png'), ('test/ETs/et_et001.png', 'test/ETs/outliers_out_et002.png'), ('test/ETs/another_et_another_et007.png', 'test/ETs/another_et_another_et009.png'), ('test/ETs/et_et005.png', 'test/ETs/outliers_out_et002.png'), ('test/ETs/another_et_another_et007.png', 'test/ETs/et_et007.png'), ('test/ETs/another_et_another_et004.png', 'test/ETs/another_et_another_et010.png'), ('test/ETs/another_et_another_et006.png', 'test/ETs/another_et_another_et007.png'), ('test/ETs/another_et_another_et005.png', 'test/ETs/another_et_another_et009.png'), ('test/ETs/et_et002.png', 'test/ETs/outliers_out_et003.png'), ('test/ETs/another_et_another_et004.png', 'test/ETs/et_et008.png'), ('test/ETs/et_et004.png', 'test/ETs/et_et008.png'), ('test/ETs/another_et_another_et005.png', 'test/ETs/et_et007.png'), ('test/ETs/another_et_another_et002.png', 'test/ETs/another_et_another_et003.png'), ('test/ETs/another_et_another_et001.png', 'test/ETs/another_et_another_et005.png'), ('test/ETs/et_et007.png', 'test/ETs/outliers_out_et002.png'), ('test/ETs/another_et_another_et009.png', 'test/ETs/et_et007.png'), ('test/ETs/et_et000.png', 'test/ETs/et_et004.png'), ('test/ETs/another_et_another_et002.png', 'test/ETs/et_et001.png'), ('test/ETs/another_et_another_et001.png', 'test/ETs/et_et003.png'), ('test/ETs/another_et_another_et003.png', 'test/ETs/et_et000.png'), ('test/ETs/et_et001.png', 'test/ETs/et_et003.png'), ('test/ETs/another_et_another_et002.png', 'test/ETs/outliers_out_et002.png'), ('test/ETs/another_et_another_et003.png', 'test/ETs/outliers_out_et001.png'), ('test/ETs/another_et_another_et007.png', 'test/ETs/et_et000.png'), ('test/ETs/another_et_another_et007.png', 'test/ETs/outliers_out_et001.png'), ('test/ETs/another_et_another_et008.png', 'test/ETs/et_et008.png'), ('test/ETs/et_et002.png', 'test/ETs/et_et004.png'), ('test/ETs/another_et_another_et004.png', 'test/ETs/et_et001.png'), ('test/ETs/another_et_another_et005.png', 'test/ETs/et_et000.png'), ('test/ETs/another_et_another_et005.png', 'test/ETs/outliers_out_et001.png'), ('test/ETs/another_et_another_et009.png', 'test/ETs/et_et000.png'), ('test/ETs/another_et_another_et002.png', 'test/ETs/another_et_another_et005.png'), ('test/ETs/another_et_another_et001.png', 'test/ETs/another_et_another_et007.png'), ('test/ETs/another_et_another_et003.png', 'test/ETs/another_et_another_et004.png'), ('test/ETs/another_et_another_et006.png', 'test/ETs/outliers_out_et002.png'), ('test/ETs/another_et_another_et009.png', 'test/ETs/outliers_out_et001.png'), ('test/ETs/another_et_another_et002.png', 'test/ETs/et_et003.png'), ('test/ETs/another_et_another_et001.png', 'test/ETs/et_et005.png'), ('test/ETs/another_et_another_et003.png', 'test/ETs/et_et002.png'), ('test/ETs/another_et_another_et010.png', 'test/ETs/et_et008.png'), ('test/ETs/et_et000.png', 'test/ETs/et_et006.png'), ('test/ETs/et_et001.png', 'test/ETs/et_et005.png'), ('test/ETs/another_et_another_et003.png', 'test/ETs/outliers_out_et003.png'), ('test/ETs/another_et_another_et007.png', 'test/ETs/et_et002.png'), ('test/ETs/another_et_another_et004.png', 'test/ETs/another_et_another_et005.png'), ('test/ETs/another_et_another_et007.png', 'test/ETs/outliers_out_et003.png'), ('test/ETs/another_et_another_et008.png', 'test/ETs/outliers_out_et002.png'), ('test/ETs/et_et008.png', 'test/ETs/outliers_out_et002.png'), ('test/ETs/et_et002.png', 'test/ETs/et_et006.png'), ('test/ETs/another_et_another_et005.png', 'test/ETs/et_et002.png'), ('test/ETs/another_et_another_et005.png', 'test/ETs/outliers_out_et003.png'), ('test/ETs/another_et_another_et009.png', 'test/ETs/et_et002.png'), ('test/ETs/another_et_another_et002.png', 'test/ETs/another_et_another_et007.png'), ('test/ETs/another_et_another_et001.png', 'test/ETs/another_et_another_et009.png'), ('test/ETs/another_et_another_et003.png', 'test/ETs/another_et_another_et006.png'), ('test/ETs/another_et_another_et009.png', 'test/ETs/outliers_out_et003.png'), ('test/ETs/another_et_another_et010.png', 'test/ETs/et_et001.png'), ('test/ETs/another_et_another_et010.png', 'test/ETs/outliers_out_et002.png'), ('test/ETs/another_et_another_et001.png', 'test/ETs/et_et007.png'), ('test/ETs/another_et_another_et003.png', 'test/ETs/et_et004.png'), ('test/ETs/et_et000.png', 'test/ETs/et_et008.png'), ('test/ETs/et_et001.png', 'test/ETs/et_et007.png'), ('test/ETs/outliers_out_et001.png', 'test/ETs/outliers_out_et003.png'), ('test/ETs/et_et003.png', 'test/ETs/outliers_out_et002.png'), ('test/ETs/et_et005.png', 'test/ETs/et_et007.png'), ('test/ETs/another_et_another_et007.png', 'test/ETs/et_et004.png'), ('test/ETs/another_et_another_et008.png', 'test/ETs/et_et003.png'), ('test/ETs/another_et_another_et005.png', 'test/ETs/another_et_another_et006.png'), ('test/ETs/another_et_another_et005.png', 'test/ETs/et_et004.png'), ('test/ETs/another_et_another_et001.png', 'test/ETs/another_et_another_et002.png'), ('test/ETs/another_et_another_et006.png', 'test/ETs/et_et005.png'), ('test/ETs/another_et_another_et009.png', 'test/ETs/et_et004.png'), ('test/ETs/et_et000.png', 'test/ETs/et_et001.png'), ('test/ETs/another_et_another_et010.png', 'test/ETs/et_et003.png'), ('test/ETs/another_et_another_et001.png', 'test/ETs/et_et000.png'), ('test/ETs/another_et_another_et003.png', 'test/ETs/another_et_another_et008.png'), ('test/ETs/another_et_another_et001.png', 'test/ETs/outliers_out_et001.png'), ('test/ETs/another_et_another_et003.png', 'test/ETs/et_et006.png'), ('test/ETs/et_et001.png', 'test/ETs/outliers_out_et001.png'), ('test/ETs/another_et_another_et007.png', 'test/ETs/another_et_another_et008.png'), ('test/ETs/et_et005.png', 'test/ETs/outliers_out_et001.png'), ('test/ETs/another_et_another_et007.png', 'test/ETs/et_et006.png'), ('test/ETs/et_et006.png', 'test/ETs/et_et008.png'), ('test/ETs/another_et_another_et008.png', 'test/ETs/et_et005.png'), ('test/ETs/another_et_another_et005.png', 'test/ETs/another_et_another_et008.png'), ('test/ETs/another_et_another_et005.png', 'test/ETs/et_et006.png'), ('test/ETs/another_et_another_et006.png', 'test/ETs/another_et_another_et009.png'), ('test/ETs/another_et_another_et001.png', 'test/ETs/another_et_another_et004.png'), ('test/ETs/another_et_another_et004.png', 'test/ETs/outliers_out_et002.png'), ('test/ETs/another_et_another_et006.png', 'test/ETs/et_et007.png'), ('test/ETs/another_et_another_et009.png', 'test/ETs/et_et006.png'), ('test/ETs/another_et_another_et010.png', 'test/ETs/et_et005.png'), ('test/ETs/another_et_another_et001.png', 'test/ETs/et_et002.png'), ('test/ETs/another_et_another_et003.png', 'test/ETs/another_et_another_et010.png'), ('test/ETs/et_et000.png', 'test/ETs/et_et003.png'), ('test/ETs/et_et001.png', 'test/ETs/et_et002.png'), ('test/ETs/et_et004.png', 'test/ETs/outliers_out_et002.png'), ('test/ETs/another_et_another_et001.png', 'test/ETs/outliers_out_et003.png'), ('test/ETs/another_et_another_et003.png', 'test/ETs/et_et008.png'), ('test/ETs/et_et001.png', 'test/ETs/outliers_out_et003.png'), ('test/ETs/et_et003.png', 'test/ETs/et_et005.png'), ('test/ETs/another_et_another_et007.png', 'test/ETs/another_et_another_et010.png'), ('test/ETs/another_et_another_et008.png', 'test/ETs/another_et_another_et009.png')]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def dino_forward(images_tensor):\n",
    "    with torch.autocast(device_type=\"cuda\", dtype=torch.float16, enabled=(device.type==\"cuda\")):\n",
    "        out = global_model.forward_features(images_tensor)\n",
    "    feats = (out[\"x_norm_clstoken\"]\n",
    "             if isinstance(out, dict) and out.get(\"x_norm_clstoken\") is not None\n",
    "             else out[\"x_norm_patchtokens\"].mean(dim=1))\n",
    "    feats = torch.nn.functional.normalize(feats, dim=1)\n",
    "    return feats.float()\n",
    "\n",
    "def load_pil(path):\n",
    "    im = Image.open(path).convert(\"RGB\")\n",
    "    return preprocess(im)\n",
    "\n",
    "def extract_embeddings(folder, batch_size=32):\n",
    "    exts = (\"*.jpg\",\"*.jpeg\",\"*.png\")\n",
    "    files = []\n",
    "    for e in exts:\n",
    "        files += glob.glob(os.path.join(folder, e))\n",
    "\n",
    "    X = []\n",
    "    batch = []\n",
    "    paths = []\n",
    "    for fp in files:\n",
    "        try:\n",
    "            batch.append(load_pil(fp))\n",
    "            paths.append(fp)\n",
    "            if len(batch) == batch_size:\n",
    "                imgs = torch.stack(batch).to(device)\n",
    "                X.append(dino_forward(imgs).cpu().numpy())\n",
    "                batch.clear()\n",
    "        except Exception as e:\n",
    "            print(f\"[WARN] skip {fp}: {e}\")\n",
    "    if batch:\n",
    "        imgs = torch.stack(batch).to(device)\n",
    "        X.append(dino_forward(imgs).cpu().numpy())\n",
    "\n",
    "    X = np.vstack(X).astype(\"float32\")\n",
    "    X /= np.linalg.norm(X, axis=1, keepdims=True) + 1e-12\n",
    "    return paths, X\n",
    "\n",
    "def pca_whiten(X, out_dim=256, seed=42, whiten=True):\n",
    "    # X: (N, D)\n",
    "    N, D = X.shape\n",
    "    max_dim = max(1, min(N - 1, D))\n",
    "    k = min(out_dim, max_dim)\n",
    "    if k < out_dim:\n",
    "        print(f\"[PCA] Reducing out_dim from {out_dim} -> {k} (N={N}, D={D})\")\n",
    "    pca = PCA(n_components=k, svd_solver=\"auto\", random_state=seed, whiten=whiten)\n",
    "    Xw = pca.fit_transform(X).astype(\"float32\")\n",
    "    Xw /= np.linalg.norm(Xw, axis=1, keepdims=True) + 1e-12\n",
    "    return Xw, pca\n",
    "\n",
    "def ann_search(X, K=40):\n",
    "    d = X.shape[1]\n",
    "    idx = faiss.IndexHNSWFlat(d, 32)\n",
    "    idx.hnsw.efConstruction = 300\n",
    "    idx.add(X)\n",
    "    idx.hnsw.efSearch = 256\n",
    "    D, I = idx.search(X, K+1)\n",
    "    return I[:, 1:], D[:, 1:]\n",
    "\n",
    "def mutual_knn_pairs(I):\n",
    "    N, K = I.shape\n",
    "    neigh = [set(row.tolist()) for row in I]\n",
    "    pairs = set()\n",
    "    for i in range(N):\n",
    "        for j in I[i]:\n",
    "            if i < j and i in neigh[j]:\n",
    "                pairs.add((i, j))\n",
    "    return pairs\n",
    "\n",
    "def jaccard_prune(pairs, I, jaccard_min=0.25):\n",
    "    neigh = [set(row.tolist()) for row in I]\n",
    "    keep = []\n",
    "    for i,j in pairs:\n",
    "        inter = len(neigh[i] & neigh[j])\n",
    "        union = len(neigh[i] | neigh[j])\n",
    "        jac = inter / (union + 1e-9)\n",
    "        if jac >= jaccard_min:\n",
    "            keep.append((i,j))\n",
    "    return keep\n",
    "\n",
    "def global_image_pairing(folder,\n",
    "                         batch_size=32,\n",
    "                         K=40,\n",
    "                         use_pca=True,\n",
    "                         pca_dim=256,\n",
    "                         jaccard_min=0.25):\n",
    "    paths, X = extract_embeddings(folder, batch_size=batch_size)\n",
    "    if use_pca:\n",
    "        X, _ = pca_whiten(X, out_dim=pca_dim)\n",
    "    I, _ = ann_search(X, K=K)\n",
    "    mk = mutual_knn_pairs(I)\n",
    "    pairs = jaccard_prune(mk, I, jaccard_min=jaccard_min)\n",
    "    path_pairs = [(paths[i], paths[j]) for (i,j) in pairs]\n",
    "    print(path_pairs)\n",
    "    return paths, X, path_pairs\n",
    "\n",
    "def image_size(path):\n",
    "    im = cv2.imread(path, cv2.IMREAD_COLOR)\n",
    "    if im is None:\n",
    "        raise FileNotFoundError(path)\n",
    "    h, w = im.shape[:2]\n",
    "    return w, h\n",
    "\n",
    "def resize_longside(im: Image.Image, longside=960):\n",
    "    w, h = im.size\n",
    "    s = longside / max(w, h)\n",
    "    if s >= 1.0:\n",
    "        return im\n",
    "    return im.resize((int(round(w*s)), int(round(h*s))), Image.BICUBIC)\n",
    "\n",
    "\n",
    "def local_matching(imgA_path, imgB_path, longside=960, max_kps=4096, thr=0.2):\n",
    "\n",
    "    A = resize_longside(Image.open(imgA_path).convert(\"RGB\"), longside=longside)\n",
    "    B = resize_longside(Image.open(imgB_path).convert(\"RGB\"), longside=longside)\n",
    "    images = [A, B]\n",
    "    image_sizes = [[(im.height, im.width) for im in images]]\n",
    "\n",
    "    inputs = local_processor(images, return_tensors=\"pt\")\n",
    "    inputs = {k: (v.to(device) if hasattr(v, \"to\") else v) for k, v in inputs.items()}\n",
    "\n",
    "    with torch.no_grad(), torch.autocast(device_type=\"cuda\", dtype=torch.float16, enabled=(device.type == \"cuda\")):\n",
    "        outputs = local_model(**inputs)\n",
    "\n",
    "    matches_list = local_processor.post_process_keypoint_matching(outputs, image_sizes, threshold=thr)\n",
    "    if not matches_list:\n",
    "        return (np.empty((0,2), np.float32),\n",
    "                np.empty((0,2), np.float32),\n",
    "                np.empty((0,), np.float32),\n",
    "                (A.size, B.size))\n",
    "\n",
    "    m = matches_list[0]\n",
    "\n",
    "    def to_numpy(t):\n",
    "        if hasattr(t, \"detach\"):\n",
    "            return t.detach().cpu().numpy().astype(np.float32)\n",
    "        return np.asarray(t, dtype=np.float32)\n",
    "\n",
    "    kpts0  = to_numpy(m[\"keypoints0\"])\n",
    "    kpts1  = to_numpy(m[\"keypoints1\"])\n",
    "    scores = to_numpy(m.get(\"matching_scores\", np.zeros((len(kpts0),), dtype=np.float32)))\n",
    "\n",
    "    if max_kps is not None and len(scores) > max_kps:\n",
    "        idx = np.argsort(scores)[-max_kps:]\n",
    "        kpts0, kpts1, scores = kpts0[idx], kpts1[idx], scores[idx]\n",
    "\n",
    "    return kpts0, kpts1, scores, (A.size, B.size)\n",
    "\n",
    "\n",
    "folder = \"train/ETs\"\n",
    "paths, X, pairs = global_image_pairing(\n",
    "        folder,\n",
    "        batch_size=60,\n",
    "        K=40,\n",
    "        use_pca=True,\n",
    "        pca_dim=256,\n",
    "        jaccard_min=0.25,\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "078816e9-b2bf-48c2-a606-028fffb865af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[pair] et_et005.png ↔ outliers_out_et003.png: 10 tentative (global) matches\n",
      "[pair] another_et_another_et007.png ↔ et_et008.png: 16 tentative (global) matches\n",
      "[pair] et_et006.png ↔ outliers_out_et002.png: 4 tentative (global) matches\n",
      "[pair] another_et_another_et008.png ↔ et_et007.png: 9 tentative (global) matches\n",
      "[pair] another_et_another_et005.png ↔ another_et_another_et010.png: 16 tentative (global) matches\n",
      "[pair] another_et_another_et004.png ↔ et_et003.png: 11 tentative (global) matches\n",
      "[pair] another_et_another_et006.png ↔ et_et000.png: 2 tentative (global) matches\n",
      "[pair] another_et_another_et009.png ↔ another_et_another_et010.png: 62 tentative (global) matches\n",
      "[pair] another_et_another_et001.png ↔ another_et_another_et006.png: 152 tentative (global) matches\n",
      "[pair] another_et_another_et006.png ↔ outliers_out_et001.png: 10 tentative (global) matches\n",
      "[pair] another_et_another_et009.png ↔ et_et008.png: 13 tentative (global) matches\n",
      "[pair] et_et007.png ↔ outliers_out_et003.png: 6 tentative (global) matches\n",
      "[pair] another_et_another_et010.png ↔ et_et007.png: 11 tentative (global) matches\n",
      "[pair] another_et_another_et001.png ↔ et_et004.png: 14 tentative (global) matches\n",
      "[pair] another_et_another_et003.png ↔ et_et001.png: 10 tentative (global) matches\n",
      "[pair] et_et001.png ↔ et_et004.png: 280 tentative (global) matches\n",
      "[pair] another_et_another_et002.png ↔ et_et005.png: 28 tentative (global) matches\n",
      "[pair] et_et003.png ↔ et_et007.png: 24 tentative (global) matches\n",
      "[pair] another_et_another_et007.png ↔ et_et001.png: 12 tentative (global) matches\n",
      "[pair] another_et_another_et008.png ↔ et_et000.png: 6 tentative (global) matches\n",
      "[pair] another_et_another_et007.png ↔ outliers_out_et002.png: 9 tentative (global) matches\n",
      "[pair] another_et_another_et008.png ↔ outliers_out_et001.png: 13 tentative (global) matches\n",
      "[pair] et_et008.png ↔ outliers_out_et001.png: 20 tentative (global) matches\n",
      "[pair] another_et_another_et004.png ↔ another_et_another_et007.png: 59 tentative (global) matches\n",
      "[pair] et_et002.png ↔ et_et008.png: 22 tentative (global) matches\n",
      "[pair] another_et_another_et004.png ↔ et_et005.png: 15 tentative (global) matches\n",
      "[pair] another_et_another_et006.png ↔ et_et002.png: 13 tentative (global) matches\n",
      "[pair] another_et_another_et009.png ↔ et_et001.png: 6 tentative (global) matches\n",
      "[pair] et_et004.png ↔ et_et005.png: 92 tentative (global) matches\n",
      "[pair] another_et_another_et010.png ↔ et_et000.png: 4 tentative (global) matches\n",
      "[pair] another_et_another_et001.png ↔ another_et_another_et008.png: 21 tentative (global) matches\n",
      "[pair] another_et_another_et003.png ↔ another_et_another_et005.png: 128 tentative (global) matches\n",
      "[pair] another_et_another_et006.png ↔ outliers_out_et003.png: 9 tentative (global) matches\n",
      "[pair] another_et_another_et010.png ↔ outliers_out_et001.png: 8 tentative (global) matches\n",
      "[pair] another_et_another_et001.png ↔ et_et006.png: 33 tentative (global) matches\n",
      "[pair] et_et001.png ↔ et_et006.png: 51 tentative (global) matches\n",
      "[pair] another_et_another_et002.png ↔ another_et_another_et009.png: 16 tentative (global) matches\n",
      "[pair] et_et000.png ↔ outliers_out_et002.png: 5 tentative (global) matches\n",
      "[pair] another_et_another_et002.png ↔ et_et007.png: 40 tentative (global) matches\n",
      "[pair] et_et003.png ↔ outliers_out_et001.png: 15 tentative (global) matches\n",
      "[pair] another_et_another_et007.png ↔ et_et003.png: 10 tentative (global) matches\n",
      "[pair] et_et005.png ↔ et_et006.png: 283 tentative (global) matches\n",
      "[pair] another_et_another_et008.png ↔ et_et002.png: 6 tentative (global) matches\n",
      "[pair] another_et_another_et008.png ↔ outliers_out_et003.png: 10 tentative (global) matches\n",
      "[pair] et_et008.png ↔ outliers_out_et003.png: 6 tentative (global) matches\n",
      "[pair] another_et_another_et004.png ↔ another_et_another_et009.png: 20 tentative (global) matches\n",
      "[pair] et_et002.png ↔ outliers_out_et002.png: 8 tentative (global) matches\n",
      "[pair] another_et_another_et004.png ↔ et_et007.png: 27 tentative (global) matches\n",
      "[pair] another_et_another_et006.png ↔ et_et004.png: 7 tentative (global) matches\n",
      "[pair] et_et004.png ↔ et_et007.png: 43 tentative (global) matches\n",
      "[pair] another_et_another_et010.png ↔ et_et002.png: 8 tentative (global) matches\n",
      "[pair] another_et_another_et001.png ↔ another_et_another_et010.png: 19 tentative (global) matches\n",
      "[pair] another_et_another_et010.png ↔ outliers_out_et003.png: 7 tentative (global) matches\n",
      "[pair] another_et_another_et002.png ↔ et_et000.png: 12 tentative (global) matches\n",
      "[pair] another_et_another_et002.png ↔ outliers_out_et001.png: 25 tentative (global) matches\n",
      "[pair] et_et003.png ↔ outliers_out_et003.png: 20 tentative (global) matches\n",
      "[pair] et_et005.png ↔ et_et008.png: 206 tentative (global) matches\n",
      "[pair] et_et006.png ↔ et_et007.png: 341 tentative (global) matches\n",
      "[pair] another_et_another_et008.png ↔ et_et004.png: 5 tentative (global) matches\n",
      "[pair] et_et002.png ↔ et_et003.png: 180 tentative (global) matches\n",
      "[pair] another_et_another_et004.png ↔ et_et000.png: 15 tentative (global) matches\n",
      "[pair] another_et_another_et006.png ↔ another_et_another_et008.png: 103 tentative (global) matches\n",
      "[pair] another_et_another_et001.png ↔ another_et_another_et003.png: 121 tentative (global) matches\n",
      "[pair] another_et_another_et004.png ↔ outliers_out_et001.png: 19 tentative (global) matches\n",
      "[pair] another_et_another_et005.png ↔ et_et008.png: 13 tentative (global) matches\n",
      "[pair] another_et_another_et006.png ↔ et_et006.png: 36 tentative (global) matches\n",
      "[pair] another_et_another_et010.png ↔ et_et004.png: 2 tentative (global) matches\n",
      "[pair] et_et004.png ↔ outliers_out_et001.png: 3 tentative (global) matches\n",
      "[pair] another_et_another_et002.png ↔ another_et_another_et004.png: 199 tentative (global) matches\n",
      "[pair] et_et000.png ↔ et_et005.png: 53 tentative (global) matches\n",
      "[pair] another_et_another_et002.png ↔ et_et002.png: 35 tentative (global) matches\n",
      "[pair] et_et003.png ↔ et_et004.png: 217 tentative (global) matches\n",
      "[pair] another_et_another_et002.png ↔ outliers_out_et003.png: 6 tentative (global) matches\n",
      "[pair] another_et_another_et003.png ↔ outliers_out_et002.png: 5 tentative (global) matches\n",
      "[pair] et_et006.png ↔ outliers_out_et001.png: 22 tentative (global) matches\n",
      "[pair] another_et_another_et008.png ↔ et_et006.png: 10 tentative (global) matches\n",
      "[pair] et_et002.png ↔ et_et005.png: 111 tentative (global) matches\n",
      "[pair] another_et_another_et004.png ↔ et_et002.png: 24 tentative (global) matches\n",
      "[pair] another_et_another_et006.png ↔ another_et_another_et010.png: 14 tentative (global) matches\n",
      "[pair] another_et_another_et005.png ↔ et_et001.png: 22 tentative (global) matches\n",
      "[pair] another_et_another_et004.png ↔ outliers_out_et003.png: 9 tentative (global) matches\n",
      "[pair] another_et_another_et006.png ↔ et_et008.png: 6 tentative (global) matches\n",
      "[pair] another_et_another_et005.png ↔ outliers_out_et002.png: 15 tentative (global) matches\n",
      "[pair] et_et004.png ↔ outliers_out_et003.png: 4 tentative (global) matches\n",
      "[pair] another_et_another_et010.png ↔ et_et006.png: 4 tentative (global) matches\n",
      "[pair] another_et_another_et002.png ↔ another_et_another_et006.png: 149 tentative (global) matches\n",
      "[pair] another_et_another_et009.png ↔ outliers_out_et002.png: 10 tentative (global) matches\n",
      "[pair] et_et000.png ↔ et_et007.png: 20 tentative (global) matches\n",
      "[pair] another_et_another_et002.png ↔ et_et004.png: 7 tentative (global) matches\n",
      "[pair] et_et003.png ↔ et_et006.png: 28 tentative (global) matches\n",
      "[pair] another_et_another_et003.png ↔ et_et003.png: 19 tentative (global) matches\n",
      "[pair] outliers_out_et001.png ↔ outliers_out_et002.png: 12 tentative (global) matches\n",
      "[pair] another_et_another_et008.png ↔ another_et_another_et010.png: 50 tentative (global) matches\n",
      "[pair] et_et006.png ↔ outliers_out_et003.png: 5 tentative (global) matches\n",
      "[pair] another_et_another_et004.png ↔ another_et_another_et006.png: 103 tentative (global) matches\n",
      "[pair] outliers_out_et002.png ↔ outliers_out_et003.png: 14 tentative (global) matches\n",
      "[pair] et_et002.png ↔ et_et007.png: 96 tentative (global) matches\n",
      "[pair] another_et_another_et004.png ↔ et_et004.png: 18 tentative (global) matches\n",
      "[pair] another_et_another_et006.png ↔ et_et001.png: 18 tentative (global) matches\n",
      "[pair] another_et_another_et005.png ↔ et_et003.png: 19 tentative (global) matches\n",
      "[pair] another_et_another_et009.png ↔ et_et003.png: 17 tentative (global) matches\n",
      "[pair] another_et_another_et002.png ↔ another_et_another_et008.png: 43 tentative (global) matches\n",
      "[pair] another_et_another_et003.png ↔ another_et_another_et007.png: 46 tentative (global) matches\n",
      "[pair] et_et000.png ↔ outliers_out_et001.png: 7 tentative (global) matches\n",
      "[pair] another_et_another_et002.png ↔ et_et006.png: 35 tentative (global) matches\n",
      "[pair] another_et_another_et001.png ↔ et_et008.png: 19 tentative (global) matches\n",
      "[pair] another_et_another_et003.png ↔ et_et005.png: 19 tentative (global) matches\n",
      "[pair] et_et001.png ↔ et_et008.png: 12 tentative (global) matches\n",
      "[pair] another_et_another_et008.png ↔ et_et001.png: 10 tentative (global) matches\n",
      "[pair] et_et003.png ↔ et_et008.png: 21 tentative (global) matches\n",
      "[pair] another_et_another_et007.png ↔ et_et005.png: 18 tentative (global) matches\n",
      "[pair] another_et_another_et004.png ↔ another_et_another_et008.png: 28 tentative (global) matches\n",
      "[pair] another_et_another_et005.png ↔ another_et_another_et007.png: 71 tentative (global) matches\n",
      "[pair] et_et002.png ↔ outliers_out_et001.png: 10 tentative (global) matches\n",
      "[pair] another_et_another_et004.png ↔ et_et006.png: 17 tentative (global) matches\n",
      "[pair] another_et_another_et006.png ↔ et_et003.png: 14 tentative (global) matches\n",
      "[pair] another_et_another_et005.png ↔ et_et005.png: 26 tentative (global) matches\n",
      "[pair] et_et004.png ↔ et_et006.png: 105 tentative (global) matches\n",
      "[pair] et_et007.png ↔ outliers_out_et001.png: 12 tentative (global) matches\n",
      "[pair] et_et007.png ↔ et_et008.png: 209 tentative (global) matches\n",
      "[pair] another_et_another_et009.png ↔ et_et005.png: 10 tentative (global) matches\n",
      "[pair] et_et000.png ↔ et_et002.png: 233 tentative (global) matches\n",
      "[pair] another_et_another_et002.png ↔ another_et_another_et010.png: 12 tentative (global) matches\n",
      "[pair] another_et_another_et001.png ↔ et_et001.png: 25 tentative (global) matches\n",
      "[pair] another_et_another_et003.png ↔ another_et_another_et009.png: 31 tentative (global) matches\n",
      "[pair] et_et000.png ↔ outliers_out_et003.png: 15 tentative (global) matches\n",
      "[pair] another_et_another_et002.png ↔ et_et008.png: 23 tentative (global) matches\n",
      "[pair] another_et_another_et001.png ↔ outliers_out_et002.png: 3 tentative (global) matches\n",
      "[pair] another_et_another_et003.png ↔ et_et007.png: 36 tentative (global) matches\n",
      "[pair] et_et001.png ↔ outliers_out_et002.png: 4 tentative (global) matches\n",
      "[pair] another_et_another_et007.png ↔ another_et_another_et009.png: 48 tentative (global) matches\n",
      "[pair] et_et005.png ↔ outliers_out_et002.png: 8 tentative (global) matches\n",
      "[pair] another_et_another_et007.png ↔ et_et007.png: 33 tentative (global) matches\n",
      "[pair] another_et_another_et004.png ↔ another_et_another_et010.png: 13 tentative (global) matches\n",
      "[pair] another_et_another_et006.png ↔ another_et_another_et007.png: 143 tentative (global) matches\n",
      "[pair] another_et_another_et005.png ↔ another_et_another_et009.png: 12 tentative (global) matches\n",
      "[pair] et_et002.png ↔ outliers_out_et003.png: 10 tentative (global) matches\n",
      "[pair] another_et_another_et004.png ↔ et_et008.png: 24 tentative (global) matches\n",
      "[pair] et_et004.png ↔ et_et008.png: 67 tentative (global) matches\n",
      "[pair] another_et_another_et005.png ↔ et_et007.png: 20 tentative (global) matches\n",
      "[pair] another_et_another_et002.png ↔ another_et_another_et003.png: 112 tentative (global) matches\n",
      "[pair] another_et_another_et001.png ↔ another_et_another_et005.png: 256 tentative (global) matches\n",
      "[pair] et_et007.png ↔ outliers_out_et002.png: 12 tentative (global) matches\n",
      "[pair] another_et_another_et009.png ↔ et_et007.png: 6 tentative (global) matches\n",
      "[pair] et_et000.png ↔ et_et004.png: 272 tentative (global) matches\n",
      "[pair] another_et_another_et002.png ↔ et_et001.png: 26 tentative (global) matches\n",
      "[pair] another_et_another_et001.png ↔ et_et003.png: 12 tentative (global) matches\n",
      "[pair] another_et_another_et003.png ↔ et_et000.png: 12 tentative (global) matches\n",
      "[pair] et_et001.png ↔ et_et003.png: 243 tentative (global) matches\n",
      "[pair] another_et_another_et002.png ↔ outliers_out_et002.png: 12 tentative (global) matches\n",
      "[pair] another_et_another_et003.png ↔ outliers_out_et001.png: 37 tentative (global) matches\n",
      "[pair] another_et_another_et007.png ↔ et_et000.png: 16 tentative (global) matches\n",
      "[pair] another_et_another_et007.png ↔ outliers_out_et001.png: 12 tentative (global) matches\n",
      "[pair] another_et_another_et008.png ↔ et_et008.png: 2 tentative (global) matches\n",
      "[pair] et_et002.png ↔ et_et004.png: 245 tentative (global) matches\n",
      "[pair] another_et_another_et004.png ↔ et_et001.png: 7 tentative (global) matches\n",
      "[pair] another_et_another_et005.png ↔ et_et000.png: 16 tentative (global) matches\n",
      "[pair] another_et_another_et005.png ↔ outliers_out_et001.png: 11 tentative (global) matches\n",
      "[pair] another_et_another_et009.png ↔ et_et000.png: 9 tentative (global) matches\n",
      "[pair] another_et_another_et002.png ↔ another_et_another_et005.png: 208 tentative (global) matches\n",
      "[pair] another_et_another_et001.png ↔ another_et_another_et007.png: 86 tentative (global) matches\n",
      "[pair] another_et_another_et003.png ↔ another_et_another_et004.png: 118 tentative (global) matches\n",
      "[pair] another_et_another_et006.png ↔ outliers_out_et002.png: 9 tentative (global) matches\n",
      "[pair] another_et_another_et009.png ↔ outliers_out_et001.png: 10 tentative (global) matches\n",
      "[pair] another_et_another_et002.png ↔ et_et003.png: 20 tentative (global) matches\n",
      "[pair] another_et_another_et001.png ↔ et_et005.png: 26 tentative (global) matches\n",
      "[pair] another_et_another_et003.png ↔ et_et002.png: 20 tentative (global) matches\n",
      "[pair] another_et_another_et010.png ↔ et_et008.png: 9 tentative (global) matches\n",
      "[pair] et_et000.png ↔ et_et006.png: 25 tentative (global) matches\n",
      "[pair] et_et001.png ↔ et_et005.png: 50 tentative (global) matches\n",
      "[pair] another_et_another_et003.png ↔ outliers_out_et003.png: 11 tentative (global) matches\n",
      "[pair] another_et_another_et007.png ↔ et_et002.png: 20 tentative (global) matches\n",
      "[pair] another_et_another_et004.png ↔ another_et_another_et005.png: 219 tentative (global) matches\n",
      "[pair] another_et_another_et007.png ↔ outliers_out_et003.png: 30 tentative (global) matches\n",
      "[pair] another_et_another_et008.png ↔ outliers_out_et002.png: 3 tentative (global) matches\n",
      "[pair] et_et008.png ↔ outliers_out_et002.png: 5 tentative (global) matches\n",
      "[pair] et_et002.png ↔ et_et006.png: 116 tentative (global) matches\n",
      "[pair] another_et_another_et005.png ↔ et_et002.png: 18 tentative (global) matches\n",
      "[pair] another_et_another_et005.png ↔ outliers_out_et003.png: 8 tentative (global) matches\n",
      "[pair] another_et_another_et009.png ↔ et_et002.png: 13 tentative (global) matches\n",
      "[pair] another_et_another_et002.png ↔ another_et_another_et007.png: 102 tentative (global) matches\n",
      "[pair] another_et_another_et001.png ↔ another_et_another_et009.png: 7 tentative (global) matches\n",
      "[pair] another_et_another_et003.png ↔ another_et_another_et006.png: 81 tentative (global) matches\n",
      "[pair] another_et_another_et009.png ↔ outliers_out_et003.png: 10 tentative (global) matches\n",
      "[pair] another_et_another_et010.png ↔ et_et001.png: 21 tentative (global) matches\n",
      "[pair] another_et_another_et010.png ↔ outliers_out_et002.png: 5 tentative (global) matches\n",
      "[pair] another_et_another_et001.png ↔ et_et007.png: 35 tentative (global) matches\n",
      "[pair] another_et_another_et003.png ↔ et_et004.png: 13 tentative (global) matches\n",
      "[pair] et_et000.png ↔ et_et008.png: 20 tentative (global) matches\n",
      "[pair] et_et001.png ↔ et_et007.png: 44 tentative (global) matches\n",
      "[pair] outliers_out_et001.png ↔ outliers_out_et003.png: 14 tentative (global) matches\n",
      "[pair] et_et003.png ↔ outliers_out_et002.png: 4 tentative (global) matches\n",
      "[pair] et_et005.png ↔ et_et007.png: 322 tentative (global) matches\n",
      "[pair] another_et_another_et007.png ↔ et_et004.png: 7 tentative (global) matches\n",
      "[pair] another_et_another_et008.png ↔ et_et003.png: 7 tentative (global) matches\n",
      "[pair] another_et_another_et005.png ↔ another_et_another_et006.png: 118 tentative (global) matches\n",
      "[pair] another_et_another_et005.png ↔ et_et004.png: 9 tentative (global) matches\n",
      "[pair] another_et_another_et001.png ↔ another_et_another_et002.png: 349 tentative (global) matches\n",
      "[pair] another_et_another_et006.png ↔ et_et005.png: 9 tentative (global) matches\n",
      "[pair] another_et_another_et009.png ↔ et_et004.png: 3 tentative (global) matches\n",
      "[pair] et_et000.png ↔ et_et001.png: 314 tentative (global) matches\n",
      "[pair] another_et_another_et010.png ↔ et_et003.png: 13 tentative (global) matches\n",
      "[pair] another_et_another_et001.png ↔ et_et000.png: 20 tentative (global) matches\n",
      "[pair] another_et_another_et003.png ↔ another_et_another_et008.png: 24 tentative (global) matches\n",
      "[pair] another_et_another_et001.png ↔ outliers_out_et001.png: 10 tentative (global) matches\n",
      "[pair] another_et_another_et003.png ↔ et_et006.png: 33 tentative (global) matches\n",
      "[pair] et_et001.png ↔ outliers_out_et001.png: 10 tentative (global) matches\n",
      "[pair] another_et_another_et007.png ↔ another_et_another_et008.png: 104 tentative (global) matches\n",
      "[pair] et_et005.png ↔ outliers_out_et001.png: 8 tentative (global) matches\n",
      "[pair] another_et_another_et007.png ↔ et_et006.png: 3 tentative (global) matches\n",
      "[pair] et_et006.png ↔ et_et008.png: 164 tentative (global) matches\n",
      "[pair] another_et_another_et008.png ↔ et_et005.png: 15 tentative (global) matches\n",
      "[pair] another_et_another_et005.png ↔ another_et_another_et008.png: 23 tentative (global) matches\n",
      "[pair] another_et_another_et005.png ↔ et_et006.png: 32 tentative (global) matches\n",
      "[pair] another_et_another_et006.png ↔ another_et_another_et009.png: 26 tentative (global) matches\n",
      "[pair] another_et_another_et001.png ↔ another_et_another_et004.png: 134 tentative (global) matches\n",
      "[pair] another_et_another_et004.png ↔ outliers_out_et002.png: 17 tentative (global) matches\n",
      "[pair] another_et_another_et006.png ↔ et_et007.png: 19 tentative (global) matches\n",
      "[pair] another_et_another_et009.png ↔ et_et006.png: 13 tentative (global) matches\n",
      "[pair] another_et_another_et010.png ↔ et_et005.png: 21 tentative (global) matches\n",
      "[pair] another_et_another_et001.png ↔ et_et002.png: 31 tentative (global) matches\n",
      "[pair] another_et_another_et003.png ↔ another_et_another_et010.png: 10 tentative (global) matches\n",
      "[pair] et_et000.png ↔ et_et003.png: 420 tentative (global) matches\n",
      "[pair] et_et001.png ↔ et_et002.png: 377 tentative (global) matches\n",
      "[pair] et_et004.png ↔ outliers_out_et002.png: 6 tentative (global) matches\n",
      "[pair] another_et_another_et001.png ↔ outliers_out_et003.png: 12 tentative (global) matches\n",
      "[pair] another_et_another_et003.png ↔ et_et008.png: 23 tentative (global) matches\n",
      "[pair] et_et001.png ↔ outliers_out_et003.png: 15 tentative (global) matches\n",
      "[pair] et_et003.png ↔ et_et005.png: 31 tentative (global) matches\n",
      "[pair] another_et_another_et007.png ↔ another_et_another_et010.png: 12 tentative (global) matches\n",
      "[pair] another_et_another_et008.png ↔ another_et_another_et009.png: 105 tentative (global) matches\n",
      "[kpts] et_et005.png: 451 keypoints\n",
      "[kpts] outliers_out_et003.png: 123 keypoints\n",
      "[kpts] another_et_another_et007.png: 296 keypoints\n",
      "[kpts] et_et008.png: 359 keypoints\n",
      "[kpts] et_et006.png: 442 keypoints\n",
      "[kpts] outliers_out_et002.png: 67 keypoints\n",
      "[kpts] another_et_another_et008.png: 276 keypoints\n",
      "[kpts] et_et007.png: 499 keypoints\n",
      "[kpts] another_et_another_et005.png: 449 keypoints\n",
      "[kpts] another_et_another_et010.png: 188 keypoints\n",
      "[kpts] another_et_another_et004.png: 400 keypoints\n",
      "[kpts] et_et003.png: 505 keypoints\n",
      "[kpts] another_et_another_et006.png: 339 keypoints\n",
      "[kpts] et_et000.png: 584 keypoints\n",
      "[kpts] another_et_another_et009.png: 219 keypoints\n",
      "[kpts] another_et_another_et001.png: 481 keypoints\n",
      "[kpts] outliers_out_et001.png: 140 keypoints\n",
      "[kpts] et_et004.png: 493 keypoints\n",
      "[kpts] another_et_another_et003.png: 319 keypoints\n",
      "[kpts] et_et001.png: 565 keypoints\n",
      "[kpts] another_et_another_et002.png: 491 keypoints\n",
      "[kpts] et_et002.png: 533 keypoints\n",
      "[done] wrote database to colmap.db\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nprefiltered_pairs = []\\nall_images = sorted({p for pair in pairs for p in pair})\\n\\nfor a, b in pairs:\\n    k0, k1, sc, _ = local_matching(a, b, longside=960, max_kps=4096, thr=0.2)\\n    if keep_pair(k0, k1, sc):\\n        prefiltered_pairs.append((a, b))\\n\\nwrite_db_from_local_matches(\\n    db_path=db_path,\\n    image_paths=all_images,\\n    pairs=prefiltered_pairs,\\n    match_func=lambda A,B: local_matching(A,B, longside=960, max_kps=4096, thr=0.2),\\n    min_matches_keep=20,   # loose; pycolmap.verify_matches will be stricter\\n    merge_px=2.0,\\n    verbose=True\\n)\\n\\n# 3) Let COLMAP do the official geometric verification (fast, C++)\\nfrom pathlib import Path\\n\\npairs_txt = \"pairs.txt\"\\nwith open(pairs_txt, \"w\") as f:\\n    for a,b in prefiltered_pairs:\\n        f.write(f\"{Path(a).name} {Path(b).name}\\n\")\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2) Write features + tentative matches into DB\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "db = pycolmap.Database(\"colmap.db\")\n",
    "db.clear_all_tables()   # drops all tables’ contents\n",
    "db.close()\n",
    "\"\"\"\n",
    "# -------------------------------\n",
    "# 1) Simple COLMAP DB helpers\n",
    "# -------------------------------\n",
    "class COLMAPDatabase(pycolmap.Database):  # thin convenience wrapper\n",
    "    pass\n",
    "\n",
    "def open_db(db_path):\n",
    "    if os.path.exists(db_path):\n",
    "        os.remove(db_path)\n",
    "    db = pycolmap.Database(); \n",
    "    db.open(db_path)\n",
    "    return db\n",
    "\n",
    "def add_image_and_camera(db: pycolmap.Database, image_path: str, default_f: float = 1200.0) -> tuple[int, tuple[int,int]]:\n",
    "    from PIL import Image\n",
    "    im = Image.open(image_path)\n",
    "    w, h = im.size\n",
    "    fx = fy = float(default_f)\n",
    "    cx, cy = w / 2.0, h / 2.0\n",
    "\n",
    "    cam = pycolmap.Camera(\n",
    "        model='SIMPLE_PINHOLE',\n",
    "        width=w, height=h,\n",
    "        params=np.array([fx, cx, cy], dtype=np.float64)\n",
    "    )\n",
    "    cam_id = db.write_camera(cam)\n",
    "\n",
    "    img = pycolmap.Image(name=Path(image_path).name, camera_id=cam_id)\n",
    "    image_id = db.write_image(img)\n",
    "    return image_id, (w, h)\n",
    "\n",
    "# -----------------------------------------\n",
    "# 2) Global per-image keypoint store/merger\n",
    "# -----------------------------------------\n",
    "class KeypointStore:\n",
    "\n",
    "    def __init__(self, merge_px=2.0):\n",
    "        self.kpts = {}         # image_name -> np.ndarray [N,2]\n",
    "        self.kdtrees = {}      # optional speed-ups (lazy)\n",
    "        self.merge_px2 = merge_px**2\n",
    "\n",
    "    def _ensure_image(self, image_name):\n",
    "        if image_name not in self.kpts:\n",
    "            self.kpts[image_name] = np.zeros((0, 2), dtype=np.float32)\n",
    "            self.kdtrees[image_name] = None\n",
    "\n",
    "    def _nn_match(self, image_name, pts):\n",
    "\n",
    "        base = self.kpts[image_name]\n",
    "        if len(base) == 0 or len(pts) == 0:\n",
    "            return np.full(len(pts), -1, np.int64), np.full(len(pts), np.inf, np.float32)\n",
    "        # (M,2) vs (N,2)\n",
    "        d2 = ((pts[:,None,:] - base[None,:,:])**2).sum(-1)  # (M,N)\n",
    "        best_idx = d2.argmin(axis=1)\n",
    "        best_d2 = d2[np.arange(len(pts)), best_idx]\n",
    "        return best_idx.astype(np.int64), best_d2.astype(np.float32)\n",
    "\n",
    "    def assign_indices(self, image_name, pts):\n",
    " \n",
    "        self._ensure_image(image_name)\n",
    "        pts = pts.astype(np.float32)\n",
    "\n",
    "        # find nearest existing kpt\n",
    "        nn_idx, nn_d2 = self._nn_match(image_name, pts)\n",
    "\n",
    "        # Decide which are new (distance too large)\n",
    "        is_new = nn_d2 > self.merge_px2\n",
    "        idx = nn_idx.copy()\n",
    "        if np.any(is_new):\n",
    "            base = self.kpts[image_name]\n",
    "            start = len(base)\n",
    "            new_pts = pts[is_new]\n",
    "            self.kpts[image_name] = np.vstack([base, new_pts])\n",
    "            # indices for new ones\n",
    "            idx[is_new] = np.arange(start, start + len(new_pts), dtype=np.int64)\n",
    "\n",
    "        return idx\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# 3) Build DB: add images, keypoints, and tentative matches\n",
    "# -----------------------------------------------------\n",
    "def write_db_from_local_matches(\n",
    "    db_path,\n",
    "    image_paths,\n",
    "    pairs,\n",
    "    match_func,\n",
    "    min_matches_keep=15,\n",
    "    merge_px=2.0,\n",
    "    verbose=True\n",
    "):\n",
    "\n",
    "\n",
    "    db = open_db(db_path)\n",
    "\n",
    "    # map name->id and keep sizes\n",
    "    name2id = {}\n",
    "    name2size = {}\n",
    "    for p in image_paths:\n",
    "        img_id, (w, h) = add_image_and_camera(db, p)\n",
    "        name2id[Path(p).name] = img_id\n",
    "        name2size[Path(p).name] = (w, h)\n",
    "\n",
    "    store = KeypointStore(merge_px=merge_px)\n",
    "\n",
    "    # We will collect per-image keypoints through the loop,\n",
    "    # but we can only call db.add_keypoints ONCE per image (after we finalize them).\n",
    "    # So we buffer matches first as \"index pairs\" and add keypoints at the end.\n",
    "    buffered_matches = defaultdict(list)  # (nameA,nameB) -> list of (i_idx, j_idx) arrays to concat\n",
    "\n",
    "    for a, b in pairs:\n",
    "        nameA = Path(a).name\n",
    "        nameB = Path(b).name\n",
    "        try:\n",
    "            k0, k1, scores, _ = match_func(a, b)\n",
    "            if len(k0) == 0:\n",
    "                continue\n",
    "\n",
    "            # Assign stable indices in the per-image stores\n",
    "            idxA = store.assign_indices(nameA, k0)  # (M,)\n",
    "            idxB = store.assign_indices(nameB, k1)  # (M,)\n",
    "\n",
    "            # (optional) keep only top matches by score here if you want\n",
    "            # e.g., top_idx = np.argsort(scores)[-4096:]\n",
    "            # idxA, idxB = idxA[top_idx], idxB[top_idx]\n",
    "\n",
    "            match_ij = np.stack([idxA, idxB], axis=1).astype(np.uint32)\n",
    "            if len(match_ij) >= min_matches_keep:\n",
    "                buffered_matches[(nameA, nameB)].append(match_ij)\n",
    "\n",
    "            if verbose:\n",
    "                print(f\"[pair ok] {nameA} - {nameB} matches={len(match_ij)}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"[pair fail] {nameA} - {nameB}: {e}\")\n",
    "\n",
    "    # Now insert keypoints (one shot per image)\n",
    "    for name, kpts in store.kpts.items():\n",
    "        img_id = name2id[name]\n",
    "        db.add_keypoints(img_id, kpts.astype(np.float32))\n",
    "\n",
    "    # Insert matches\n",
    "    for (nameA, nameB), chunks in buffered_matches.items():\n",
    "        if not chunks:\n",
    "            continue\n",
    "        ij = np.vstack(chunks).astype(np.uint32)\n",
    "\n",
    "        idA, idB = name2id[nameA], name2id[nameB]\n",
    "        # enforce id order for COLMAP\n",
    "        if idA > idB:\n",
    "            id1, id2 = idB, idA\n",
    "            matches = ij[:, [1, 0]]\n",
    "        else:\n",
    "            id1, id2 = idA, idB\n",
    "            matches = ij\n",
    "\n",
    "        db.add_matches(id1, id2, matches)\n",
    "\n",
    "    db.commit()\n",
    "    db.close()\n",
    "\n",
    "\n",
    "    # 1) Build your prefiltered_pairs (list of (A,B))\n",
    "def keep_pair(k0, k1, scores,\n",
    "              min_matches=25, mean_thr=0.25, std_max=0.35):\n",
    "    if len(scores) < min_matches:\n",
    "        return False\n",
    "    m = float(scores.mean()) if len(scores) else 0.0\n",
    "    s = float(scores.std())  if len(scores) else 1.0\n",
    "    return (m >= mean_thr) and (s <= std_max)\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "# --- Utilities ---\n",
    "\n",
    "def get_original_wh(img_path):\n",
    "    w, h = Image.open(img_path).size\n",
    "    return float(w), float(h)\n",
    "\n",
    "def scale_keypoints_to_original(kpts_pair_resized, orig_w, orig_h, res_w, res_h):\n",
    "    # Keypoints are (x,y) in resized image; map back to original pixel coords\n",
    "    sx, sy = orig_w / res_w, orig_h / res_h\n",
    "    return (kpts_pair_resized * np.array([sx, sy], np.float32)).astype(np.float32)\n",
    "\n",
    "class GlobalKeypointIndexer:\n",
    "    \"\"\"\n",
    "    Maintains a per-image global keypoint array and provides\n",
    "    mapping from new (pair-local) keypoints to global indices,\n",
    "    merging points that are within 'merge_px' in the *original resolution*.\n",
    "    \"\"\"\n",
    "    def __init__(self, merge_px=2.0):\n",
    "        self.kpts = {}          # img_path -> np.ndarray [N,2] float32 (original-res coords)\n",
    "        self.nn = {}            # img_path -> NearestNeighbors\n",
    "        self.merge_px = float(merge_px)\n",
    "\n",
    "    def _fit_nn(self, img):\n",
    "        if len(self.kpts[img]) == 0:\n",
    "            self.nn[img] = None\n",
    "            return\n",
    "        nn = NearestNeighbors(n_neighbors=1, algorithm='auto')\n",
    "        nn.fit(self.kpts[img])\n",
    "        self.nn[img] = nn\n",
    "\n",
    "    def _ensure(self, img):\n",
    "        if img not in self.kpts:\n",
    "            self.kpts[img] = np.empty((0, 2), np.float32)\n",
    "            self.nn[img] = None\n",
    "\n",
    "    def map_and_add(self, img, new_pts):\n",
    "        \"\"\"\n",
    "        new_pts: (M,2) float32 in original-res coords for 'img'\n",
    "        Returns: (M,) int64 global indices for each input point\n",
    "        \"\"\"\n",
    "        self._ensure(img)\n",
    "        if new_pts.size == 0:\n",
    "            return np.empty((0,), np.int64)\n",
    "\n",
    "        if self.nn[img] is None or len(self.kpts[img]) == 0:\n",
    "            # first points for this image\n",
    "            start = len(self.kpts[img])\n",
    "            self.kpts[img] = np.vstack([self.kpts[img], new_pts])\n",
    "            idx = np.arange(start, start + len(new_pts), dtype=np.int64)\n",
    "            self._fit_nn(img)\n",
    "            return idx\n",
    "\n",
    "        # query nearest existing to decide merge vs append\n",
    "        dists, nbrs = self.nn[img].kneighbors(new_pts, n_neighbors=1, return_distance=True)\n",
    "        dists = dists.ravel()\n",
    "        nbrs = nbrs.ravel()\n",
    "\n",
    "        to_merge = dists <= self.merge_px\n",
    "        to_add   = ~to_merge\n",
    "\n",
    "        idx = np.empty((len(new_pts),), np.int64)\n",
    "        # merged points keep neighbor's index\n",
    "        idx[to_merge] = nbrs[to_merge]\n",
    "\n",
    "        new_pts_to_add = new_pts[to_add]\n",
    "        start = len(self.kpts[img])\n",
    "        self.kpts[img] = np.vstack([self.kpts[img], new_pts_to_add])\n",
    "        idx[to_add] = np.arange(start, start + len(new_pts_to_add), dtype=np.int64)\n",
    "\n",
    "        self._fit_nn(img)\n",
    "        return idx\n",
    "\n",
    "# --- Glue: accumulate global keypoints and write DB ---\n",
    "\n",
    "def build_db_from_local_matches(db_path, pairs, local_match_func,\n",
    "                                longside=960, max_kps=4096, thr=0.2,\n",
    "                                merge_px=2.0, default_fov_px=1_200.0, verbose=True):\n",
    "    \"\"\"\n",
    "    pairs: list of (imgA_path, imgB_path)\n",
    "    local_match_func(imgA, imgB, longside, max_kps, thr) -> kpts0_resized, kpts1_resized, scores, ((resW_A,resH_A),(resW_B,resH_B))\n",
    "    Writes:\n",
    "      - global per-image keypoints (original resolution)\n",
    "      - matches as indices into those global arrays\n",
    "    \"\"\"\n",
    "    db = pycolmap.Database(db_path)\n",
    "\n",
    "    img_name_to_id = {}\n",
    "    img_name_to_wh = {}\n",
    "    img_name_to_cam = {}\n",
    "\n",
    "    #get all unique image names\n",
    "    all_images = sorted({p for ab in pairs for p in ab})\n",
    "    for img_path in all_images:\n",
    "        w, h = get_original_wh(img_path)\n",
    "        img_name = Path(img_path).name\n",
    "        # camera: fx = fy = default_fov_px, cx = w/2, cy = h/2\n",
    "        cam = pycolmap.Camera(model='SIMPLE_PINHOLE',\n",
    "                              width=int(w), height=int(h),\n",
    "                              params=np.array([float(default_fov_px), w/2.0, h/2.0], dtype=np.float64))\n",
    "        cam_id = db.write_camera(cam)\n",
    "        img_row = pycolmap.Image(name=img_name, camera_id=cam_id)\n",
    "        img_id = db.write_image(img_row)\n",
    "\n",
    "        img_name_to_id[img_name] = img_id\n",
    "        img_name_to_wh[img_name] = (w, h)\n",
    "        img_name_to_cam[img_name] = cam_id\n",
    "    indexer = GlobalKeypointIndexer(merge_px=merge_px)\n",
    "\n",
    "    # Store pair matches as global indices to write later\n",
    "    pending_matches = []\n",
    "\n",
    "    for a_path, b_path in pairs:\n",
    "        k0_r, k1_r, scores, ((resW_A, resH_A), (resW_B, resH_B)) = local_match_func(\n",
    "            a_path, b_path, longside=longside, max_kps=max_kps, thr=thr\n",
    "        )\n",
    "\n",
    "        nameA = Path(a_path).name\n",
    "        nameB = Path(b_path).name\n",
    "        wA, hA = img_name_to_wh[nameA]\n",
    "        wB, hB = img_name_to_wh[nameB]\n",
    "        k0 = scale_keypoints_to_original(k0_r, wA, hA, float(resW_A), float(resH_A))\n",
    "        k1 = scale_keypoints_to_original(k1_r, wB, hB, float(resW_B), float(resH_B))\n",
    "\n",
    "        # map to global indices with deduplication\n",
    "        idxA = indexer.map_and_add(a_path, k0)\n",
    "        idxB = indexer.map_and_add(b_path, k1)\n",
    "\n",
    "        if len(idxA) > 0:\n",
    "            ij = np.stack([idxA.astype(np.uint32), idxB.astype(np.uint32)], axis=1)\n",
    "            pending_matches.append((img_name_to_id[nameA], img_name_to_id[nameB], ij))\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"[pair] {nameA} ↔ {nameB}: {len(idxA)} tentative (global) matches\")\n",
    "\n",
    "    for img_path, kpts in indexer.kpts.items():\n",
    "        name = Path(img_path).name\n",
    "        img_id = img_name_to_id[name]\n",
    "        db.write_keypoints(img_id, kpts.astype(np.float32))\n",
    "        if verbose:\n",
    "            print(f\"[kpts] {name}: {len(kpts)} keypoints\")\n",
    "\n",
    "    for idA, idB, ij in pending_matches:\n",
    "        db.write_matches(idA, idB, ij.astype(np.uint32))\n",
    "\n",
    "    db.close()\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"[done] wrote database to {db_path}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "db_path = \"colmap.db\"\n",
    "build_db_from_local_matches(db_path, pairs, local_matching,\n",
    "                                longside=960, max_kps=4096, thr=0.2,\n",
    "                                merge_px=2.0, default_fov_px=1_200.0, verbose=True)\n",
    "\n",
    "    \n",
    "\"\"\"\n",
    "prefiltered_pairs = []\n",
    "all_images = sorted({p for pair in pairs for p in pair})\n",
    "\n",
    "for a, b in pairs:\n",
    "    k0, k1, sc, _ = local_matching(a, b, longside=960, max_kps=4096, thr=0.2)\n",
    "    if keep_pair(k0, k1, sc):\n",
    "        prefiltered_pairs.append((a, b))\n",
    "\n",
    "write_db_from_local_matches(\n",
    "    db_path=db_path,\n",
    "    image_paths=all_images,\n",
    "    pairs=prefiltered_pairs,\n",
    "    match_func=lambda A,B: local_matching(A,B, longside=960, max_kps=4096, thr=0.2),\n",
    "    min_matches_keep=20,   # loose; pycolmap.verify_matches will be stricter\n",
    "    merge_px=2.0,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# 3) Let COLMAP do the official geometric verification (fast, C++)\n",
    "from pathlib import Path\n",
    "\n",
    "pairs_txt = \"pairs.txt\"\n",
    "with open(pairs_txt, \"w\") as f:\n",
    "    for a,b in prefiltered_pairs:\n",
    "        f.write(f\"{Path(a).name} {Path(b).name}\\n\")\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ca65cc50-8522-48d8-9fdd-67f117631f86",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I20251014 23:23:02.010472 126058120586816 misc.cc:44] \n",
      "==============================================================================\n",
      "Feature matching\n",
      "==============================================================================\n",
      "I20251014 23:23:02.014770 126058128979520 sift.cc:1434] Creating SIFT CPU feature matcher\n",
      "I20251014 23:23:02.015120 126058533746240 sift.cc:1434] Creating SIFT CPU feature matcher\n",
      "I20251014 23:23:02.015423 126058380645952 sift.cc:1434] Creating SIFT CPU feature matcher\n",
      "I20251014 23:23:02.015930 126058657478208 sift.cc:1434] Creating SIFT CPU feature matcher\n",
      "I20251014 23:23:02.016322 126058649085504 sift.cc:1434] Creating SIFT CPU feature matcher\n",
      "I20251014 23:23:02.016709 126058137372224 sift.cc:1434] Creating SIFT CPU feature matcher\n",
      "I20251014 23:23:02.017004 126058525353536 sift.cc:1434] Creating SIFT CPU feature matcher\n",
      "I20251014 23:23:02.017344 126058516960832 sift.cc:1434] Creating SIFT CPU feature matcher\n",
      "I20251014 23:23:02.017708 126058397431360 sift.cc:1434] Creating SIFT CPU feature matcher\n",
      "I20251014 23:23:02.018072 126058389038656 sift.cc:1434] Creating SIFT CPU feature matcher\n",
      "I20251014 23:23:02.018447 126058145764928 sift.cc:1434] Creating SIFT CPU feature matcher\n",
      "I20251014 23:23:02.018757 126058296768064 sift.cc:1434] Creating SIFT CPU feature matcher\n",
      "I20251014 23:23:02.018820 126058120586816 pairing.cc:795] Importing image pairs...\n",
      "I20251014 23:23:02.021507 126058120586816 pairing.cc:828] Matching block [1/1]\n",
      "I20251014 23:23:02.089322 126058120586816 feature_matching.cc:47] in 0.068s\n",
      "I20251014 23:23:02.089377 126058120586816 timer.cc:91] Elapsed time: 0.001 [minutes]\n",
      "I20251014 23:23:02.100447 126066262986752 incremental_pipeline.cc:254] Loading database\n",
      "I20251014 23:23:02.147367 126066262986752 database_cache.cc:66] Loading rigs...\n",
      "I20251014 23:23:02.147705 126066262986752 database_cache.cc:76]  0 in 0.000s\n",
      "I20251014 23:23:02.147756 126066262986752 database_cache.cc:84] Loading cameras...\n",
      "I20251014 23:23:02.148316 126066262986752 database_cache.cc:102]  22 in 0.001s\n",
      "I20251014 23:23:02.148354 126066262986752 database_cache.cc:110] Loading frames...\n",
      "I20251014 23:23:02.148641 126066262986752 database_cache.cc:127]  0 in 0.000s\n",
      "I20251014 23:23:02.148668 126066262986752 database_cache.cc:135] Loading matches...\n",
      "I20251014 23:23:02.154429 126066262986752 database_cache.cc:140]  112 in 0.006s\n",
      "I20251014 23:23:02.154470 126066262986752 database_cache.cc:156] Loading images...\n",
      "I20251014 23:23:02.169607 126066262986752 database_cache.cc:241]  22 in 0.015s (connected 20)\n",
      "I20251014 23:23:02.169695 126066262986752 database_cache.cc:252] Building correspondence graph...\n",
      "W20251014 23:23:02.169878 126066262986752 correspondence_graph.cc:148] Duplicate correspondence between point2D_idx=90 in image_id=2 and point2D_idx=301 in image_id=5\n",
      "W20251014 23:23:02.169930 126066262986752 correspondence_graph.cc:148] Duplicate correspondence between point2D_idx=229 in image_id=2 and point2D_idx=195 in image_id=5\n",
      "W20251014 23:23:02.170032 126066262986752 correspondence_graph.cc:148] Duplicate correspondence between point2D_idx=154 in image_id=4 and point2D_idx=389 in image_id=5\n",
      "W20251014 23:23:02.170081 126066262986752 correspondence_graph.cc:148] Duplicate correspondence between point2D_idx=383 in image_id=4 and point2D_idx=195 in image_id=5\n",
      "I20251014 23:23:02.170754 126066262986752 database_cache.cc:279]  in 0.001s (ignored 47)\n",
      "I20251014 23:23:02.170793 126066262986752 timer.cc:91] Elapsed time: 0.000 [minutes]\n",
      "I20251014 23:23:02.176266 126066262986752 incremental_pipeline.cc:300] Finding good initial image pair\n",
      "I20251014 23:23:02.185021 126066262986752 incremental_pipeline.cc:324] Registering initial image pair #13 and #15\n",
      "I20251014 23:23:02.186934 126066262986752 incremental_pipeline.cc:338] Global bundle adjustment\n",
      "I20251014 23:23:02.299377 126066262986752 incremental_pipeline.cc:428] Registering image #12 (num_reg_frames=2)\n",
      "I20251014 23:23:02.299424 126066262986752 incremental_pipeline.cc:431] => Image sees 187 / 544 points\n",
      "I20251014 23:23:02.322259 126066262986752 incremental_pipeline.cc:43] Retriangulation and Global bundle adjustment\n",
      "I20251014 23:23:02.361006 126066262986752 incremental_pipeline.cc:428] Registering image #11 (num_reg_frames=3)\n",
      "I20251014 23:23:02.361055 126066262986752 incremental_pipeline.cc:431] => Image sees 303 / 565 points\n",
      "I20251014 23:23:02.389196 126066262986752 incremental_pipeline.cc:43] Retriangulation and Global bundle adjustment\n",
      "I20251014 23:23:02.432114 126066262986752 incremental_pipeline.cc:428] Registering image #14 (num_reg_frames=4)\n",
      "I20251014 23:23:02.432162 126066262986752 incremental_pipeline.cc:431] => Image sees 352 / 477 points\n",
      "I20251014 23:23:02.464706 126066262986752 incremental_pipeline.cc:43] Retriangulation and Global bundle adjustment\n",
      "I20251014 23:23:02.524881 126066262986752 incremental_pipeline.cc:428] Registering image #17 (num_reg_frames=5)\n",
      "I20251014 23:23:02.524931 126066262986752 incremental_pipeline.cc:431] => Image sees 127 / 429 points\n",
      "I20251014 23:23:02.615325 126066262986752 incremental_pipeline.cc:43] Retriangulation and Global bundle adjustment\n",
      "I20251014 23:23:02.665192 126066262986752 incremental_pipeline.cc:428] Registering image #16 (num_reg_frames=6)\n",
      "I20251014 23:23:02.665241 126066262986752 incremental_pipeline.cc:431] => Image sees 152 / 429 points\n",
      "I20251014 23:23:02.703446 126066262986752 incremental_pipeline.cc:43] Retriangulation and Global bundle adjustment\n",
      "I20251014 23:23:02.763973 126066262986752 incremental_pipeline.cc:428] Registering image #18 (num_reg_frames=7)\n",
      "I20251014 23:23:02.764023 126066262986752 incremental_pipeline.cc:431] => Image sees 300 / 487 points\n",
      "I20251014 23:23:02.822665 126066262986752 incremental_pipeline.cc:43] Retriangulation and Global bundle adjustment\n",
      "I20251014 23:23:02.879893 126066262986752 incremental_pipeline.cc:428] Registering image #19 (num_reg_frames=8)\n",
      "I20251014 23:23:02.879937 126066262986752 incremental_pipeline.cc:431] => Image sees 251 / 313 points\n",
      "I20251014 23:23:02.927660 126066262986752 incremental_pipeline.cc:43] Retriangulation and Global bundle adjustment\n",
      "I20251014 23:23:02.998267 126066262986752 incremental_pipeline.cc:428] Registering image #2 (num_reg_frames=9)\n",
      "I20251014 23:23:02.998317 126066262986752 incremental_pipeline.cc:431] => Image sees 48 / 475 points\n",
      "I20251014 23:23:03.001017 126066262986752 incremental_pipeline.cc:442] => Could not register, trying another image.\n",
      "I20251014 23:23:03.001055 126066262986752 incremental_pipeline.cc:428] Registering image #3 (num_reg_frames=9)\n",
      "I20251014 23:23:03.001066 126066262986752 incremental_pipeline.cc:431] => Image sees 37 / 275 points\n",
      "I20251014 23:23:03.004884 126066262986752 incremental_pipeline.cc:442] => Could not register, trying another image.\n",
      "I20251014 23:23:03.004910 126066262986752 incremental_pipeline.cc:428] Registering image #1 (num_reg_frames=9)\n",
      "I20251014 23:23:03.004917 126066262986752 incremental_pipeline.cc:431] => Image sees 36 / 466 points\n",
      "I20251014 23:23:03.008157 126066262986752 incremental_pipeline.cc:442] => Could not register, trying another image.\n",
      "I20251014 23:23:03.008185 126066262986752 incremental_pipeline.cc:43] Retriangulation and Global bundle adjustment\n",
      "I20251014 23:23:03.018374 126066262986752 incremental_pipeline.cc:428] Registering image #2 (num_reg_frames=9)\n",
      "I20251014 23:23:03.018428 126066262986752 incremental_pipeline.cc:431] => Image sees 48 / 475 points\n",
      "I20251014 23:23:03.022110 126066262986752 incremental_pipeline.cc:442] => Could not register, trying another image.\n",
      "I20251014 23:23:03.022135 126066262986752 incremental_pipeline.cc:428] Registering image #3 (num_reg_frames=9)\n",
      "I20251014 23:23:03.022142 126066262986752 incremental_pipeline.cc:431] => Image sees 37 / 275 points\n",
      "I20251014 23:23:03.025969 126066262986752 incremental_pipeline.cc:442] => Could not register, trying another image.\n",
      "I20251014 23:23:03.026004 126066262986752 incremental_pipeline.cc:428] Registering image #1 (num_reg_frames=9)\n",
      "I20251014 23:23:03.026013 126066262986752 incremental_pipeline.cc:431] => Image sees 36 / 466 points\n",
      "I20251014 23:23:03.029399 126066262986752 incremental_pipeline.cc:442] => Could not register, trying another image.\n",
      "I20251014 23:23:03.029429 126066262986752 incremental_pipeline.cc:584] Keeping successful reconstruction\n",
      "I20251014 23:23:03.029753 126066262986752 incremental_pipeline.cc:300] Finding good initial image pair\n",
      "I20251014 23:23:03.043822 126066262986752 incremental_pipeline.cc:324] Registering initial image pair #2 and #6\n",
      "I20251014 23:23:03.044679 126066262986752 incremental_pipeline.cc:338] Global bundle adjustment\n",
      "I20251014 23:23:03.105830 126066262986752 incremental_pipeline.cc:428] Registering image #1 (num_reg_frames=2)\n",
      "I20251014 23:23:03.105878 126066262986752 incremental_pipeline.cc:431] => Image sees 115 / 466 points\n",
      "I20251014 23:23:03.139215 126066262986752 incremental_pipeline.cc:43] Retriangulation and Global bundle adjustment\n",
      "I20251014 23:23:03.177742 126066262986752 incremental_pipeline.cc:428] Registering image #5 (num_reg_frames=3)\n",
      "I20251014 23:23:03.177800 126066262986752 incremental_pipeline.cc:431] => Image sees 190 / 410 points\n",
      "I20251014 23:23:03.195244 126066262986752 incremental_pipeline.cc:43] Retriangulation and Global bundle adjustment\n",
      "I20251014 23:23:03.229187 126066262986752 incremental_pipeline.cc:428] Registering image #4 (num_reg_frames=4)\n",
      "I20251014 23:23:03.229237 126066262986752 incremental_pipeline.cc:431] => Image sees 176 / 353 points\n",
      "I20251014 23:23:03.269482 126066262986752 incremental_pipeline.cc:43] Retriangulation and Global bundle adjustment\n",
      "I20251014 23:23:03.303427 126066262986752 incremental_pipeline.cc:428] Registering image #3 (num_reg_frames=5)\n",
      "I20251014 23:23:03.303473 126066262986752 incremental_pipeline.cc:431] => Image sees 145 / 275 points\n",
      "I20251014 23:23:03.338066 126066262986752 incremental_pipeline.cc:43] Retriangulation and Global bundle adjustment\n",
      "I20251014 23:23:03.378446 126066262986752 incremental_pipeline.cc:428] Registering image #7 (num_reg_frames=6)\n",
      "I20251014 23:23:03.378496 126066262986752 incremental_pipeline.cc:431] => Image sees 143 / 236 points\n",
      "I20251014 23:23:03.407320 126066262986752 incremental_pipeline.cc:43] Retriangulation and Global bundle adjustment\n",
      "I20251014 23:23:03.451233 126066262986752 incremental_pipeline.cc:428] Registering image #8 (num_reg_frames=7)\n",
      "I20251014 23:23:03.451280 126066262986752 incremental_pipeline.cc:431] => Image sees 90 / 240 points\n",
      "I20251014 23:23:03.479376 126066262986752 incremental_pipeline.cc:43] Retriangulation and Global bundle adjustment\n",
      "I20251014 23:23:03.522093 126066262986752 incremental_pipeline.cc:428] Registering image #9 (num_reg_frames=8)\n",
      "I20251014 23:23:03.522141 126066262986752 incremental_pipeline.cc:431] => Image sees 58 / 145 points\n",
      "I20251014 23:23:03.540104 126066262986752 incremental_pipeline.cc:43] Retriangulation and Global bundle adjustment\n",
      "I20251014 23:23:03.582595 126066262986752 incremental_pipeline.cc:428] Registering image #18 (num_reg_frames=9)\n",
      "I20251014 23:23:03.582642 126066262986752 incremental_pipeline.cc:431] => Image sees 58 / 487 points\n",
      "I20251014 23:23:03.588950 126066262986752 incremental_pipeline.cc:442] => Could not register, trying another image.\n",
      "I20251014 23:23:03.588992 126066262986752 incremental_pipeline.cc:428] Registering image #17 (num_reg_frames=9)\n",
      "I20251014 23:23:03.589004 126066262986752 incremental_pipeline.cc:431] => Image sees 53 / 429 points\n",
      "I20251014 23:23:03.591714 126066262986752 incremental_pipeline.cc:442] => Could not register, trying another image.\n",
      "I20251014 23:23:03.591738 126066262986752 incremental_pipeline.cc:428] Registering image #10 (num_reg_frames=9)\n",
      "I20251014 23:23:03.591745 126066262986752 incremental_pipeline.cc:431] => Image sees 34 / 81 points\n",
      "I20251014 23:23:03.592114 126066262986752 incremental_pipeline.cc:442] => Could not register, trying another image.\n",
      "I20251014 23:23:03.592139 126066262986752 incremental_pipeline.cc:43] Retriangulation and Global bundle adjustment\n",
      "I20251014 23:23:03.596966 126066262986752 incremental_pipeline.cc:428] Registering image #18 (num_reg_frames=9)\n",
      "I20251014 23:23:03.596997 126066262986752 incremental_pipeline.cc:431] => Image sees 58 / 487 points\n",
      "I20251014 23:23:03.603691 126066262986752 incremental_pipeline.cc:442] => Could not register, trying another image.\n",
      "I20251014 23:23:03.603759 126066262986752 incremental_pipeline.cc:428] Registering image #17 (num_reg_frames=9)\n",
      "I20251014 23:23:03.603772 126066262986752 incremental_pipeline.cc:431] => Image sees 53 / 429 points\n",
      "I20251014 23:23:03.606734 126066262986752 incremental_pipeline.cc:442] => Could not register, trying another image.\n",
      "I20251014 23:23:03.606760 126066262986752 incremental_pipeline.cc:428] Registering image #10 (num_reg_frames=9)\n",
      "I20251014 23:23:03.606768 126066262986752 incremental_pipeline.cc:431] => Image sees 34 / 81 points\n",
      "I20251014 23:23:03.621346 126066262986752 incremental_pipeline.cc:43] Retriangulation and Global bundle adjustment\n",
      "I20251014 23:23:03.650666 126066262986752 incremental_pipeline.cc:428] Registering image #18 (num_reg_frames=10)\n",
      "I20251014 23:23:03.650719 126066262986752 incremental_pipeline.cc:431] => Image sees 58 / 487 points\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reconstructions: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I20251014 23:23:03.657375 126066262986752 incremental_pipeline.cc:442] => Could not register, trying another image.\n",
      "I20251014 23:23:03.657412 126066262986752 incremental_pipeline.cc:428] Registering image #17 (num_reg_frames=10)\n",
      "I20251014 23:23:03.657423 126066262986752 incremental_pipeline.cc:431] => Image sees 53 / 429 points\n",
      "I20251014 23:23:03.661606 126066262986752 incremental_pipeline.cc:442] => Could not register, trying another image.\n",
      "I20251014 23:23:03.661650 126066262986752 incremental_pipeline.cc:43] Retriangulation and Global bundle adjustment\n",
      "I20251014 23:23:03.666985 126066262986752 incremental_pipeline.cc:584] Keeping successful reconstruction\n",
      "I20251014 23:23:03.667090 126066262986752 incremental_pipeline.cc:235] => Relaxing the initialization constraints.\n",
      "I20251014 23:23:03.667209 126066262986752 incremental_pipeline.cc:300] Finding good initial image pair\n",
      "I20251014 23:23:03.667217 126066262986752 incremental_pipeline.cc:304] => No good initial image pair found.\n",
      "I20251014 23:23:03.667219 126066262986752 incremental_pipeline.cc:547] Discarding reconstruction due to no initial pair\n",
      "I20251014 23:23:03.667232 126066262986752 incremental_pipeline.cc:244] => Relaxing the initialization constraints.\n",
      "I20251014 23:23:03.667288 126066262986752 incremental_pipeline.cc:300] Finding good initial image pair\n",
      "I20251014 23:23:03.667315 126066262986752 incremental_pipeline.cc:304] => No good initial image pair found.\n",
      "I20251014 23:23:03.667320 126066262986752 incremental_pipeline.cc:547] Discarding reconstruction due to no initial pair\n",
      "I20251014 23:23:03.667333 126066262986752 incremental_pipeline.cc:235] => Relaxing the initialization constraints.\n",
      "I20251014 23:23:03.667390 126066262986752 incremental_pipeline.cc:300] Finding good initial image pair\n",
      "I20251014 23:23:03.667394 126066262986752 incremental_pipeline.cc:304] => No good initial image pair found.\n",
      "I20251014 23:23:03.667396 126066262986752 incremental_pipeline.cc:547] Discarding reconstruction due to no initial pair\n",
      "I20251014 23:23:03.667406 126066262986752 incremental_pipeline.cc:244] => Relaxing the initialization constraints.\n",
      "I20251014 23:23:03.667458 126066262986752 incremental_pipeline.cc:300] Finding good initial image pair\n",
      "I20251014 23:23:03.667463 126066262986752 incremental_pipeline.cc:304] => No good initial image pair found.\n",
      "I20251014 23:23:03.667465 126066262986752 incremental_pipeline.cc:547] Discarding reconstruction due to no initial pair\n",
      "I20251014 23:23:03.667475 126066262986752 timer.cc:91] Elapsed time: 0.026 [minutes]\n"
     ]
    }
   ],
   "source": [
    "def run_pycolmap_verify_and_map(db_path: str, image_root: str, out_dir: str):\n",
    "    \"\"\"\n",
    "    1) Geometric verification in C++ (populates two-view geometry).\n",
    "    2) Incremental mapping to produce reconstructions.\n",
    "    \"\"\"\n",
    "    db = pycolmap.Database(db_path)\n",
    "    pair_ids = db.read_two_view_geometry_num_inliers()[0]  #verified\n",
    "    if len(pair_ids) == 0:\n",
    "        pair_ids = db.read_all_matches()[0]\n",
    "    db.close()\n",
    "\n",
    "    db = pycolmap.Database(db_path)\n",
    "    id2name = {img.image_id: img.name for img in db.read_all_images()}\n",
    "    pairs_txt = Path(out_dir) / \"pairs.txt\"\n",
    "    pairs_txt.parent.mkdir(parents=True, exist_ok=True)\n",
    "    with pairs_txt.open(\"w\") as f:\n",
    "        for pid in pair_ids:\n",
    "            i, j = pycolmap.Database.pair_id_to_image_pair(pid)\n",
    "            f.write(f\"{id2name[i]} {id2name[j]}\\n\")\n",
    "    db.close()\n",
    "\n",
    "    # 1) geometric verification\n",
    "    pycolmap.verify_matches(\n",
    "        database_path=db_path,\n",
    "        pairs_path=str(pairs_txt),\n",
    "        options=pycolmap.TwoViewGeometryOptions()  # tune if needed\n",
    "    )\n",
    "\n",
    "    # 2) incremental mapping\n",
    "    mapper_opts = pycolmap.IncrementalPipelineOptions()\n",
    "    mapper_opts.min_model_size = 3\n",
    "    mapper_opts.min_num_matches = 30\n",
    "    recon_dir = Path(out_dir) / \"sparse\"\n",
    "    recon_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    maps = pycolmap.incremental_mapping(\n",
    "        database_path=db_path,\n",
    "        image_path=image_root,\n",
    "        output_path=str(recon_dir),\n",
    "        options=mapper_opts\n",
    "    )\n",
    "    return maps\n",
    "maps = run_pycolmap_verify_and_map(\n",
    "    db_path=db_path,\n",
    "    image_root=folder,\n",
    "    out_dir=\"colmap_outputs\"\n",
    ")\n",
    "\n",
    "print(\"Reconstructions:\", len(maps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "469836b4-eee5-4b2c-a2ca-4e0d4048546e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[eval] Similarity (max threshold) transform:\n",
      " [[ 0.84558241  0.12501454 -0.86572881  0.30679416]\n",
      " [-0.06760999  1.20985295  0.10867074  0.15638522]\n",
      " [ 0.87209168 -0.02741908  0.84783779  0.77256832]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "\n",
      "[mAA] dataset=ETs scene=ET => 8.33%\n",
      "mAA: 0.08333333333333333\n",
      "\n",
      "[eval] Similarity (max threshold) transform:\n",
      " [[ 1.19760937 -0.0112851   0.11114377  0.30589692]\n",
      " [ 0.00518928  1.20098376  0.066027    0.2160948 ]\n",
      " [-0.11159463 -0.06526209  1.19584112  0.56190442]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "\n",
      "[mAA] dataset=ETs scene=another_ET => 11.90%\n",
      "mAA: 0.11904761904761904\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import math\n",
    "import pandas as pd\n",
    "\n",
    "### UTILISING PYCOLMAP DOCUMENTATION -> https://colmap.github.io/format.html\n",
    "### EVALUATION IS ACCORDING TO IMC CHALLENGE 2024!\n",
    "\"\"\"def camera_centers(Rs, ts):\n",
    "    Rt = np.transpose(Rs, (0, 2, 1))\n",
    "    return (-Rt @ ts[..., None])[..., 0]\n",
    "\n",
    "def umeyama_similarity(X, Y, with_scale=True): ## Horn's method\n",
    "    X = np.asarray(X, np.float64)\n",
    "    Y = np.asarray(Y, np.float64)\n",
    "    muX, muY = X.mean(0), Y.mean(0)\n",
    "    Xc, Yc = X - muX, Y - muY\n",
    "    C = (Yc.T @ Xc) / X.shape[0]\n",
    "    U, S, Vt = np.linalg.svd(C)\n",
    "    R = U @ np.diag([1, 1, np.sign(np.linalg.det(U @ Vt))]) @ Vt\n",
    "    s = 1.0\n",
    "    if with_scale:\n",
    "        var_X = (Xc**2).sum() / X.shape[0]\n",
    "        s = (S * np.array([1, 1, np.sign(np.linalg.det(U @ Vt))])).sum() / var_X\n",
    "    t = muY - s * (R @ muX)\n",
    "    return float(s), R, t\n",
    "\n",
    "def apply_similarity(C, s, R, t):\n",
    "    return (s * (C @ R.T)) + t\n",
    "\n",
    "def best_center_alignment(C_pred, C_gt, sample_mode=\"ransac\", n_iters=2000, rng=0):\n",
    "    N = len(C_pred)\n",
    "    rng = np.random.default_rng(rng)\n",
    "    # 2% of scene extent as selection threshold for model choice\n",
    "    sel_thresh = 0.02 * np.linalg.norm(C_gt.max(0) - C_gt.min(0))\n",
    "    best_score, best = -1, (1.0, np.eye(3), np.zeros(3), np.zeros(N, bool))\n",
    "\n",
    "    # If scene is small, try exhaustive triplets; else random RANSAC\n",
    "    max_trip = 150_000\n",
    "    use_exhaustive = math.comb(N, 3) <= max_trip\n",
    "    if sample_mode == \"exhaustive\" and use_exhaustive:\n",
    "        from itertools import combinations\n",
    "        triplets = combinations(range(N), 3)\n",
    "    else:\n",
    "        triplets = [tuple(rng.choice(N, 3, replace=False)) for _ in range(n_iters)]\n",
    "\n",
    "    for tri in triplets:\n",
    "        i, j, k = tri\n",
    "        s, R, t = umeyama_similarity(C_pred[[i, j, k]], C_gt[[i, j, k]], with_scale=True)\n",
    "        C_al = apply_similarity(C_pred, s, R, t)\n",
    "        inl = np.linalg.norm(C_al - C_gt, axis=1) <= sel_thresh\n",
    "        sc = int(inl.sum())\n",
    "        if sc > best_score:\n",
    "            best_score = sc\n",
    "            best = (s, R, t, inl)\n",
    "    return best\"\"\"\n",
    "\n",
    "\"\"\"def compute_mAA(R_pred, t_pred, R_gt, t_gt, thresholds_m=None, seed=0):\n",
    "    R_pred = np.asarray(R_pred, float); t_pred = np.asarray(t_pred, float)\n",
    "    R_gt   = np.asarray(R_gt, float);   t_gt   = np.asarray(t_gt, float)\n",
    "    assert R_pred.shape == R_gt.shape and t_pred.shape == t_gt.shape\n",
    "    C_pred = camera_centers(R_pred, t_pred)\n",
    "    C_gt   = camera_centers(R_gt,   t_gt)\n",
    "\n",
    "    s, R, t, _ = best_center_alignment(C_pred, C_gt, sample_mode=\"ransac\", n_iters=2000, rng=seed)\n",
    "    C_al = apply_similarity(C_pred, s, R, t)\n",
    "    d = np.linalg.norm(C_al - C_gt, axis=1)\n",
    "\n",
    "    if thresholds_m is None:\n",
    "        thresholds_m = [0.01, 0.02, 0.05, 0.1, 0.2]  # meters (example)\n",
    "    accs = [(d <= thr).mean() for thr in thresholds_m]\n",
    "    return {\n",
    "        \"mAA\": float(np.mean(accs)),\n",
    "        \"per_threshold\": dict(zip(thresholds_m, accs)),\n",
    "        \"similarity\": {\"scale\": s, \"R\": R, \"t\": t},\n",
    "        \"aligned_centers\": C_al,\n",
    "        \"center_errors\": d,\n",
    "    }\"\"\"\n",
    "\n",
    "_EPS = np.finfo(float).eps * 4.0\n",
    "\n",
    "def vector_norm(data, axis=None, out=None):\n",
    "    data = np.array(data, dtype=np.float64, copy=True)\n",
    "    if out is None:\n",
    "        if data.ndim == 1:\n",
    "            return math.sqrt(np.dot(data, data))\n",
    "        data *= data\n",
    "        out = np.atleast_1d(np.sum(data, axis=axis))\n",
    "        np.sqrt(out, out)\n",
    "        return out\n",
    "    data *= data\n",
    "    np.sum(data, axis=axis, out=out)\n",
    "    np.sqrt(out, out)\n",
    "    return None\n",
    "\n",
    "\n",
    "\n",
    "def quaternion_matrix(quaternion):\n",
    "    q = np.array(quaternion, dtype=np.float64, copy=True)\n",
    "    n = np.dot(q, q)\n",
    "    if n < _EPS:\n",
    "        return np.identity(4)\n",
    "    q *= math.sqrt(2.0 / n)\n",
    "    q = np.outer(q, q)\n",
    "    return np.array(\n",
    "        [\n",
    "            [1.0 - q[2, 2] - q[3, 3], q[1, 2] - q[3, 0],     q[1, 3] + q[2, 0],     0.0],\n",
    "            [q[1, 2] + q[3, 0],     1.0 - q[1, 1] - q[3, 3], q[2, 3] - q[1, 0],     0.0],\n",
    "            [q[1, 3] - q[2, 0],     q[2, 3] + q[1, 0],     1.0 - q[1, 1] - q[2, 2], 0.0],\n",
    "            [0.0, 0.0, 0.0, 1.0],\n",
    "        ]\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "def affine_matrix_from_points(v0, v1, shear=False, scale=True, usesvd=True):\n",
    "    v0 = np.array(v0, dtype=np.float64, copy=True)\n",
    "    v1 = np.array(v1, dtype=np.float64, copy=True)\n",
    "    ndims = v0.shape[0]\n",
    "    if ndims < 2 or v0.shape[1] < ndims or v0.shape != v1.shape:\n",
    "        raise ValueError(\"input arrays are of wrong shape or type\")\n",
    "    # center\n",
    "    t0 = -np.mean(v0, axis=1); M0 = np.identity(ndims + 1); M0[:ndims, ndims] = t0; v0 += t0.reshape(ndims, 1)\n",
    "    t1 = -np.mean(v1, axis=1); M1 = np.identity(ndims + 1); M1[:ndims, ndims] = t1; v1 += t1.reshape(ndims, 1)\n",
    "    if shear:\n",
    "        A = np.concatenate((v0, v1), axis=0)\n",
    "        u, s, vh = np.linalg.svd(A.T)\n",
    "        vh = vh[:ndims].T\n",
    "        B = vh[:ndims]; C = vh[ndims: 2 * ndims]\n",
    "        t = np.dot(C, np.linalg.pinv(B))\n",
    "        t = np.concatenate((t, np.zeros((ndims, 1))), axis=1)\n",
    "        M = np.vstack((t, ((0.0,) * ndims) + (1.0,)))\n",
    "    elif usesvd or ndims != 3:\n",
    "        u, s, vh = np.linalg.svd(np.dot(v1, v0.T))\n",
    "        R = np.dot(u, vh)\n",
    "        if np.linalg.det(R) < 0.0:\n",
    "            R -= np.outer(u[:, ndims - 1], vh[ndims - 1, :] * 2.0)\n",
    "            s[-1] *= -1.0\n",
    "        M = np.identity(ndims + 1)\n",
    "        M[:ndims, :ndims] = R\n",
    "    else:\n",
    "        xx, yy, zz = np.sum(v0 * v1, axis=1)\n",
    "        xy, yz, zx = np.sum(v0 * np.roll(v1, -1, axis=0), axis=1)\n",
    "        xz, yx, zy = np.sum(v0 * np.roll(v1, -2, axis=0), axis=1)\n",
    "        N = [\n",
    "            [xx + yy + zz, 0.0, 0.0, 0.0],\n",
    "            [yz - zy, xx - yy - zz, 0.0, 0.0],\n",
    "            [zx - xz, xy + yx, yy - xx - zz, 0.0],\n",
    "            [xy - yx, zx + xz, yz + zy, zz - xx - yy],\n",
    "        ]\n",
    "        w, V = np.linalg.eigh(N); q = V[:, np.argmax(w)]; q /= vector_norm(q)\n",
    "        M = quaternion_matrix(q)\n",
    "    if scale and not shear:\n",
    "        v0 *= v0; v1 *= v1\n",
    "        M[:ndims, :ndims] *= math.sqrt(np.sum(v1) / np.sum(v0))\n",
    "    M = np.dot(np.linalg.inv(M1), np.dot(M, M0))\n",
    "    M /= M[ndims, ndims]\n",
    "    return M\n",
    "\n",
    "def register_by_Horn(ev_coord, gt_coord, ransac_threshold, inl_cf, strict_cf):\n",
    "    # Filter invalid\n",
    "    idx_cams = np.all(np.isfinite(ev_coord), axis=0)\n",
    "    ev_coord = ev_coord[:, idx_cams]\n",
    "    gt_coord = gt_coord[:, idx_cams]\n",
    "\n",
    "    n = ev_coord.shape[1]\n",
    "    r = ransac_threshold.shape[0]\n",
    "    ransac_threshold = np.expand_dims(ransac_threshold, axis=0)\n",
    "    ransac_threshold2 = ransac_threshold**2\n",
    "    ev_coord_1 = np.vstack((ev_coord, np.ones(n)))\n",
    "\n",
    "    max_no_inl = np.zeros((1, r))\n",
    "    best_inl_err = np.full(r, np.Inf)\n",
    "    best_transf_matrix = np.zeros((r, 4, 4))\n",
    "    best_err = np.full((n, r), np.Inf)\n",
    "    strict_inl = np.full((n, r), False)\n",
    "    triplets_used = np.zeros((3, r))\n",
    "\n",
    "    for ii in range(n-2):\n",
    "        for jj in range(ii+1, n-1):\n",
    "            for kk in range(jj+1, n):\n",
    "                i = [ii, jj, kk]\n",
    "                if np.all(strict_inl[i]):\n",
    "                    continue\n",
    "                T = affine_matrix_from_points(ev_coord[:, i], gt_coord[:, i], usesvd=False)\n",
    "                rotranslated = np.matmul(T[:3], ev_coord_1)\n",
    "                err = np.sum((rotranslated - gt_coord)**2, axis=0)  # squared\n",
    "                inl = np.expand_dims(err, axis=1) < ransac_threshold2\n",
    "                no_inl = np.sum(inl, axis=0)\n",
    "                to_ref = np.squeeze(((no_inl > 2) & (no_inl > max_no_inl * inl_cf)), axis=0)\n",
    "                for q in np.argwhere(to_ref):\n",
    "                    qq = q[0]\n",
    "                    if np.any(np.all((np.expand_dims(inl[:, qq], axis=1) == inl[:, :qq]), axis=0)):\n",
    "                        continue\n",
    "                    T = affine_matrix_from_points(ev_coord[:, inl[:, qq]], gt_coord[:, inl[:, qq]])\n",
    "                    rotranslated = np.matmul(T[:3], ev_coord_1)\n",
    "                    err_ref = np.sum((rotranslated - gt_coord)**2, axis=0)\n",
    "                    err_ref_sum = np.sum(err_ref, axis=0)\n",
    "                    err_ref = np.expand_dims(err_ref, axis=1)\n",
    "                    inl_ref = err_ref < ransac_threshold2\n",
    "                    no_inl_ref = np.sum(inl_ref, axis=0)\n",
    "                    to_update = np.squeeze((no_inl_ref > max_no_inl) | ((no_inl_ref == max_no_inl) & (err_ref_sum < best_inl_err)), axis=0)\n",
    "                    if np.any(to_update):\n",
    "                        triplets_used[0, to_update] = ii\n",
    "                        triplets_used[1, to_update] = jj\n",
    "                        triplets_used[2, to_update] = kk\n",
    "                        max_no_inl[:, to_update] = no_inl_ref[to_update]\n",
    "                        best_err[:, to_update] = np.sqrt(err_ref)  # back to euclidean\n",
    "                        best_inl_err[to_update] = err_ref_sum\n",
    "                        strict_inl[:, to_update] = (best_err[:, to_update] < (strict_cf * ransac_threshold[:, to_update]))\n",
    "                        best_transf_matrix[to_update] = T\n",
    "\n",
    "    best_model = {\n",
    "        \"valid_cams\": idx_cams,\n",
    "        \"no_inl\": max_no_inl,\n",
    "        \"err\": best_err,\n",
    "        \"triplets_used\": triplets_used,\n",
    "        \"transf_matrix\": best_transf_matrix\n",
    "    }\n",
    "    return best_model\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def mAA_on_cameras(err, thresholds, n, skip_top_thresholds, to_dec):\n",
    "    aux = err[:, skip_top_thresholds:] < np.expand_dims(np.asarray(thresholds[skip_top_thresholds:]), axis=0)\n",
    "    return np.sum(np.maximum(np.sum(aux, axis=0) - to_dec, 0)) / (len(thresholds[skip_top_thresholds:]) * (n - to_dec))\n",
    "    \n",
    "def get_camera_centers_from_df(df):\n",
    "    out = {}\n",
    "    for _, row in df.iterrows():\n",
    "        fname = row['image_path']\n",
    "        R = np.array([float(x) for x in row['rotation_matrix'].split(';')]).reshape(3,3)\n",
    "        t = np.array([float(x) for x in row['translation_vector'].split(';')]).reshape(3)\n",
    "        center = -R.T @ t\n",
    "        out[fname] = center\n",
    "    return out\n",
    "\n",
    "def evaluate_rec(gt_df, user_df, thresholds, inl_cf=0.8, strict_cf=0.5, skip_top_thresholds=2, to_dec=3, verbose=True):\n",
    "    ucameras = get_camera_centers_from_df(user_df)\n",
    "    gcameras = get_camera_centers_from_df(gt_df)\n",
    "\n",
    "    good = [k for k in gcameras.keys() if k in ucameras]\n",
    "    n = len(good)\n",
    "    u = np.zeros((3, n)); g = np.zeros((3, n))\n",
    "    for i, k in enumerate(good):\n",
    "        u[:, i] = ucameras[k]\n",
    "        g[:, i] = gcameras[k]\n",
    "\n",
    "    model = register_by_Horn(u, g, np.asarray(thresholds), inl_cf, strict_cf)\n",
    "\n",
    "    if verbose and len(thresholds) > 0:\n",
    "        T = np.squeeze(model['transf_matrix'][-1])\n",
    "        print(\"\\n[eval] Similarity (max threshold) transform:\\n\", T)\n",
    "\n",
    "    m = gt_df.shape[0]\n",
    "    mAA = mAA_on_cameras(model[\"err\"], thresholds, m, skip_top_thresholds, to_dec)\n",
    "    return mAA, model\n",
    "\n",
    "\n",
    "# --- Quaternion -> rotation (right-handed, COLMAP qvec = [qw, qx, qy, qz]) ---\n",
    "def qvec_to_rotmat(q):\n",
    "    qw, qx, qy, qz = map(float, q)\n",
    "    # normalized just in case\n",
    "    s = qw*qw + qx*qx + qy*qy + qz*qz\n",
    "    if s == 0:\n",
    "        return np.eye(3, dtype=np.float64)\n",
    "    qw, qx, qy, qz = qw/np.sqrt(s), qx/np.sqrt(s), qy/np.sqrt(s), qz/np.sqrt(s)\n",
    "    R = np.array([\n",
    "        [1-2*(qy*qy+qz*qz),   2*(qx*qy - qz*qw),   2*(qx*qz + qy*qw)],\n",
    "        [2*(qx*qy + qz*qw),   1-2*(qx*qx+qz*qz),   2*(qy*qz - qx*qw)],\n",
    "        [2*(qx*qz - qy*qw),   2*(qy*qz + qx*qw),   1-2*(qx*qx+qy*qy)]\n",
    "    ], dtype=np.float64)\n",
    "    return R\n",
    "\n",
    "def read_reconstruction_poses(model_dir,dataset,scene):\n",
    "    \"\"\"\n",
    "    Returns: dict[name] = {'R': (3,3), 't': (3,), 'C': (3,)} \n",
    "    where [R|t] maps world -> camera, and C is camera center in world coord.\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "    images_txt_path = model_dir + \"/\" + \"images.txt\"\n",
    "    with open(images_txt_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        lines = [ln.strip() for ln in f if ln.strip() and not ln.startswith(\"#\")]\n",
    "    for i in range(0, len(lines), 2):\n",
    "        hdr = lines[i].split()\n",
    "\n",
    "        # IMAGE_ID, QW, QX, QY, QZ, TX, TY, TZ, CAMERA_ID, NAME\n",
    "        image_id = int(hdr[0])\n",
    "        qw, qx, qy, qz = map(float, hdr[1:5])\n",
    "        tx, ty, tz = map(float, hdr[5:8])\n",
    "        cam_id = int(hdr[8])\n",
    "        name = \" \".join(hdr[9:])\n",
    "        q = np.array([qw, qx, qy, qz], dtype=np.float64)\n",
    "        t = np.array([tx, ty, tz], dtype=np.float64)\n",
    "\n",
    "        R = qvec_to_rotmat(q)\n",
    "\n",
    "        r_str = \";\".join(f\"{x:.9f}\" for x in R.reshape(-1).tolist())\n",
    "        t_str = \";\".join(f\"{x:.9f}\" for x in t.reshape(-1).tolist())\n",
    "        rows.append({\n",
    "            \"dataset\": dataset,\n",
    "            \"scene\": scene,\n",
    "            \"image_path\": name,\n",
    "            \"rotation_matrix\": r_str,\n",
    "            \"translation_vector\": t_str\n",
    "        })\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "def parse_semicolon_vec(s):\n",
    "    return np.array([float(x) for x in s.split(\";\")], dtype=float)\n",
    "\n",
    "def parse_semicolon_mat9(s):\n",
    "    # 9 values row-major separated by ';'\n",
    "    vals = [float(x) for x in s.split(\";\")]\n",
    "    assert len(vals) == 9, f\"Expected 9 values, got {len(vals)}\"\n",
    "    return np.array(vals, dtype=float).reshape(3, 3)\n",
    "\n",
    "def read_gt_csv(path, dataset=None, scene=None):\n",
    "    \"\"\"\n",
    "    Returns dict: {basename: (R_gt, t_gt)}.\n",
    "    Expects columns: dataset,scene,image,rotation_matrix,translation_vector\n",
    "    \"\"\"\n",
    "    out = {}\n",
    "    with open(path, \"r\", newline=\"\") as f:\n",
    "        rdr = csv.DictReader(f)\n",
    "        for row in rdr:\n",
    "            if dataset and row.get(\"dataset\") != dataset:\n",
    "                continue\n",
    "            if scene and row.get(\"scene\") != scene:\n",
    "                continue\n",
    "            name = os.path.basename(row[\"image\"])\n",
    "            R = parse_semicolon_mat9(row[\"rotation_matrix\"])\n",
    "            t = parse_semicolon_vec(row[\"translation_vector\"])\n",
    "            out[name] = (R, t)\n",
    "    return out\n",
    "\n",
    "\n",
    "def evaluate_mAA_from_model(model_dir, gt_csv_path, thresholds_csv,\n",
    "                            dataset=None, scene=None, seed=0, verbose=True):\n",
    "    \"\"\"\n",
    "    model_dir: path to COLMAP reconstruction (e.g., 'path/to/sparse/0')\n",
    "    gt_csv_path: CSV with GT poses\n",
    "    thresholds_m: iterable of thresholds in meters (or your linear unit)\n",
    "    dataset/scene: optional filters for GT rows\n",
    "    \"\"\"\n",
    "\n",
    "    inl_cf=0.8\n",
    "    strict_cf=0.5\n",
    "    skip_top_thresholds=0\n",
    "    to_dec=3\n",
    "    pred_df = read_reconstruction_poses(model_dir,dataset,scene)\n",
    "    gt = []\n",
    "    with open(gt_csv_path, \"r\", newline=\"\") as f:\n",
    "        for row in csv.DictReader(f):\n",
    "            if row[\"dataset\"].strip() != dataset or row[\"scene\"].strip() != scene:\n",
    "                continue\n",
    "            gt.append({\n",
    "                \"dataset\": row[\"dataset\"].strip(),\n",
    "                \"scene\": row[\"scene\"].strip(),\n",
    "                \"image_path\": row[\"image\"].strip() if \"image\" in row else row[\"image_path\"].strip(),\n",
    "                \"rotation_matrix\": row[\"rotation_matrix\"].strip(),\n",
    "                \"translation_vector\": row[\"translation_vector\"].strip(),\n",
    "            })\n",
    "    gt_df = pd.DataFrame(gt)\n",
    "\n",
    "\n",
    "    thr_map = read_thresholds_csv(thresholds_csv) if thresholds_csv else None\n",
    "    thresholds = thresholds_for(thr_map, dataset, scene)\n",
    "\n",
    "    mAA, model = evaluate_rec(\n",
    "        gt_df, pred_df,\n",
    "        thresholds=thresholds,\n",
    "        inl_cf=inl_cf,\n",
    "        strict_cf=strict_cf,\n",
    "        skip_top_thresholds=skip_top_thresholds,\n",
    "        to_dec=to_dec,\n",
    "        verbose=verbose\n",
    "    )\n",
    "    if verbose:\n",
    "        print(f\"\\n[mAA] dataset={dataset} scene={scene} => {mAA*100:.2f}%\")\n",
    "\n",
    "    return mAA, model, pred_df, gt_df\n",
    "\n",
    "def read_thresholds_csv(path):\n",
    "    \"\"\"\n",
    "    Returns dict[(dataset, scene)] = list_of_thresholds(floats)\n",
    "    CSV columns: dataset,scene,thresholds (semicolon-separated meters)\n",
    "    \"\"\"\n",
    "    out = {}\n",
    "    with open(path, \"r\", newline=\"\") as f:\n",
    "        for row in csv.DictReader(f):\n",
    "            ds = row[\"dataset\"].strip()\n",
    "            sc = row[\"scene\"].strip()\n",
    "            thr = [float(x) for x in row[\"thresholds\"].split(\";\") if x.strip()]\n",
    "            out[(ds, sc)] = thr\n",
    "    return out\n",
    "def thresholds_for(thr_map, dataset, scene, fallback=(0.01, 0.02, 0.05, 0.1, 0.2)):\n",
    "    return thr_map.get((dataset, scene), list(fallback))\n",
    "\n",
    "\n",
    "\n",
    "model_dir = \"colmap_outputs/sparse/0\"\n",
    "model_dir1 = \"colmap_outputs/sparse/1\"\n",
    "gt_csv = \"train_labels.csv\"\n",
    "threshold_csv = \"train_thresholds.csv\"\n",
    "\n",
    "thresholds_map = read_thresholds_csv(threshold_csv)\n",
    "ds, sc = \"ETs\", \"ET\"\n",
    "ds1, sc1 = \"ETs\", \"another_ET\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "mAA, model, pred_df, gt_df = evaluate_mAA_from_model(\n",
    "model_dir, gt_csv,\n",
    "threshold_csv,\n",
    "dataset=ds, scene=sc, verbose=True\n",
    " )\n",
    "print(\"mAA:\",mAA)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "mAA1, model1, pred_df1, gt_df1 = evaluate_mAA_from_model(\n",
    "model_dir1, gt_csv,\n",
    "threshold_csv,\n",
    "dataset=ds1, scene=sc1, verbose=True\n",
    " )\n",
    "print(\"mAA:\",mAA1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb2a0ed-446c-489e-9272-31070749530c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (WSL: .pyenv)",
   "language": "python",
   "name": ".pyenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
